{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parcours Ingénieur Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projet 8 : Participez à une compétition Kaggle !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table des matières:\n",
    "* [Introduction](#0)\n",
    "* [1. Cleansing des données](#1)\n",
    "    * [1.1 Installation des packages](#1.1)\n",
    "    * [1.2 Chargement et visualisation des données](#1.2)\n",
    "    * [1.3 Traitements de nettoyage](#1.3)   \n",
    "        * [1.3.1 Analyse des emojis](#1.3.1)\n",
    "        * [1.3.2 Suppression des digits et autres caractères indésirables](#1.3.2)\n",
    "        * [1.3.3 Suppression des contractions](#1.3.3)\n",
    "        * [1.3.4 Gestion des fautes d'orthographe](#1.3.4)\n",
    "        * [1.3.5 Détection de langue](#1.3.5)\n",
    "* [2. Data augmentation](#2)\n",
    "    * [2.1 Installation des packages](#2.1)\n",
    "    * [2.2 Méthode des synonymes](#2.2)\n",
    "* [3. Modélisation](#3)\n",
    "    * [3.1 Configuration du TPU](#3.1)\n",
    "    * [3.2 Fonction d'encodage](#3.2)\n",
    "    * [3.3 Construction du modèle](#3.3)\n",
    "    * [3.4 Entrainement](#3.4)\n",
    "    * [3.5 Soumission du modèle](#3.5)\n",
    "    * [3.6 Mode opératoire et tests](#3.6)\n",
    "* [4. Résultats](#4)\n",
    "* [Conclusion](#5)\n",
    "* [Sources](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction<a class=\"anchor\" id=\"0\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A travers ce notebook, je vais vous exposer dans le détail ce que j'ai réalisé dans le cadre de ce nouveau projet pour le parcours d'ingénieur machine learning d'OpenClassrooms. \n",
    "<p>Le but est de participer à une compétition Kaggle. Je me suis donc inscrit à la compétition \"Jigsaw Multilingual Toxic Comment Classification\" dont le but est de venir classifier de la donnée textuelle. Il s'agit donc d'une problématique de NLP tournée autour de l'utilisation d'un accélérateur conçu par Google, le TPU, et permettant de tester et mettre en pratique les modèles pré entrainés les plus performants à l'heure actuelle. La donnée à classifier correspond à des commentaires récupérés sur le \"Wikipedia talk page comments\". L'intérêt est de construire un modèle capable de détecter automatiquement si un commentaire est considéré comme toxique ou non. En d'autres termes, mettre en place un modérateur automatique.\n",
    "<p>Dans un premier temps, je vais présenter ce que j'ai réalisé comme nettoyage en détaillant chacune des stratégies. Ensuite, j'aborderai la partie data augmentation que j'ai souhaité tester dans le cadre de ce projet. Enfin, la dernière partie sera consacrée à la modélisation et au mode opératoire adopté pour trouver la meilleure combinaison possible entre algorithme de machine learning et data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfYZ6AYNFCeB"
   },
   "source": [
    "## 1. Cleansing des données<a class=\"anchor\" id=\"1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RyX3BD63n4OW"
   },
   "source": [
    "### 1.1 Installation des packages<a class=\"anchor\" id=\"1.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Commençons par installer l'ensemble des librairies que j'utiliserai dans le cadre du preprocessing des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 67277,
     "status": "ok",
     "timestamp": 1594977466520,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "AimgJhwu4gV6",
    "outputId": "5376ada9-74ec-4ed0-8248-bc767cc13eaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting emoji\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/40/8d/521be7f0091fe0f2ae690cc044faf43e3445e0ff33c574eae752dd7e39fa/emoji-0.5.4.tar.gz (43kB)\n",
      "\r",
      "\u001b[K     |███████▌                        | 10kB 16.3MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████                 | 20kB 2.2MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 30kB 2.9MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████████████▏ | 40kB 3.2MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 51kB 2.0MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: emoji\n",
      "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for emoji: filename=emoji-0.5.4-cp36-none-any.whl size=42176 sha256=0a662047e674c20723f9219ade3cc23b3f0a3eaa46ebafd692550a9d39de3da2\n",
      "  Stored in directory: /root/.cache/pip/wheels/2a/a9/0a/4f8e8cce8074232aba240caca3fade315bb49fac68808d1a9c\n",
      "Successfully built emoji\n",
      "Installing collected packages: emoji\n",
      "Successfully installed emoji-0.5.4\n",
      "Collecting demoji\n",
      "  Downloading https://files.pythonhosted.org/packages/da/0b/d008f26ebbfd86d21117267e627f2f7359c76e5ecbeba08d8f631f4092c4/demoji-0.2.1-py2.py3-none-any.whl\n",
      "Collecting colorama\n",
      "  Downloading https://files.pythonhosted.org/packages/c9/dc/45cdef1b4d119eb96316b3117e6d5708a08029992b2fee2c143c7a0a5cc5/colorama-0.4.3-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests<3.0.0 in /usr/local/lib/python3.6/dist-packages (from demoji) (2.23.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from demoji) (49.1.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (1.24.3)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0->demoji) (2020.6.20)\n",
      "Installing collected packages: colorama, demoji\n",
      "Successfully installed colorama-0.4.3 demoji-0.2.1\n",
      "Collecting spacy_cld\n",
      "  Downloading https://files.pythonhosted.org/packages/e3/3b/f5344007259b5beb0a8e0d7b9e6b0d2c5c4dcfe674bc94b7497bcc201ee0/spacy_cld-0.1.0.tar.gz\n",
      "Requirement already satisfied: spacy<3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy_cld) (2.2.4)\n",
      "Collecting pycld2>=0.31\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/d2/8b0def84a53c88d0eb27c67b05269fbd16ad68df8c78849e7b5d65e6aec3/pycld2-0.41.tar.gz (41.4MB)\n",
      "\u001b[K     |████████████████████████████████| 41.4MB 100kB/s \n",
      "\u001b[?25hRequirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.0.0->spacy_cld) (1.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.0.0->spacy_cld) (49.1.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.0.0->spacy_cld) (4.41.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.0.0->spacy_cld) (3.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.0.0->spacy_cld) (0.4.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.0.0->spacy_cld) (2.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.0.0->spacy_cld) (0.7.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.0.0->spacy_cld) (1.0.2)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.0.0->spacy_cld) (1.1.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.0.0->spacy_cld) (1.18.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.0.0->spacy_cld) (1.0.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.0.0->spacy_cld) (2.23.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<3.0.0,>=2.0.0->spacy_cld) (7.4.0)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.0.0->spacy_cld) (1.7.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.0.0->spacy_cld) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.0.0->spacy_cld) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.0.0->spacy_cld) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.0.0,>=2.0.0->spacy_cld) (2.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy<3.0.0,>=2.0.0->spacy_cld) (3.1.0)\n",
      "Building wheels for collected packages: spacy-cld, pycld2\n",
      "  Building wheel for spacy-cld (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for spacy-cld: filename=spacy_cld-0.1.0-cp36-none-any.whl size=4065 sha256=c6c86da076fe93db87c10155a0e274590f2d6274850cc48288144f7ddb24de0a\n",
      "  Stored in directory: /root/.cache/pip/wheels/7e/a6/a5/604befa6807cc78a6852be9e933c080362b2498fca796cd34e\n",
      "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pycld2: filename=pycld2-0.41-cp36-cp36m-linux_x86_64.whl size=9833495 sha256=f5fffa1da5322e1d801eae3acb1acae865000d94579144473f3fcf5f4e129caa\n",
      "  Stored in directory: /root/.cache/pip/wheels/c6/8f/e9/08a1a8932a490175bd140206cd86a3dbcfc70498100de11079\n",
      "Successfully built spacy-cld pycld2\n",
      "Installing collected packages: pycld2, spacy-cld\n",
      "Successfully installed pycld2-0.41 spacy-cld-0.1.0\n",
      "Collecting autocorrect\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/5b/6510d8370201fc96cbb773232c2362079389ed3285b0b1c6a297ef6eadc0/autocorrect-2.0.0.tar.gz (1.8MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 2.8MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: autocorrect\n",
      "  Building wheel for autocorrect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for autocorrect: filename=autocorrect-2.0.0-cp36-none-any.whl size=1811641 sha256=055976f1def3c45f792430c8e4bc611523b680c0834275f82d3064f19b208250\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/06/bc/e66f28d72bed29591eadc79cebb2e7964ad0282804ab233da3\n",
      "Successfully built autocorrect\n",
      "Installing collected packages: autocorrect\n",
      "Successfully installed autocorrect-2.0.0\n",
      "Collecting pandarallel\n",
      "  Downloading https://files.pythonhosted.org/packages/99/06/bd582106766c483d6da51c05b0cdd7cb61894bb843c7ecc4789032232327/pandarallel-1.4.8.tar.gz\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from pandarallel) (0.3.2)\n",
      "Building wheels for collected packages: pandarallel\n",
      "  Building wheel for pandarallel (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pandarallel: filename=pandarallel-1.4.8-cp36-none-any.whl size=16112 sha256=b0fb6b629fcbc7bbf246989fc86a88c36f4f729f1f31a4e554e65148522e6cbb\n",
      "  Stored in directory: /root/.cache/pip/wheels/75/a2/85/b45be2e86d86e9ec5da6d05c4b994d18c81abe76e3f39415aa\n",
      "Successfully built pandarallel\n",
      "Installing collected packages: pandarallel\n",
      "Successfully installed pandarallel-1.4.8\n",
      "Collecting xx_ent_wiki_sm==2.2.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/xx_ent_wiki_sm-2.2.0/xx_ent_wiki_sm-2.2.0.tar.gz (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 1.2MB/s \n",
      "\u001b[?25hRequirement already satisfied: spacy>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from xx_ent_wiki_sm==2.2.0) (2.2.4)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (0.4.1)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.1.3)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (49.1.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (0.7.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (2.23.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (7.4.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.18.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (2.0.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.0.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (4.41.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (3.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.0.2)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (2020.6.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (3.0.4)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (1.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.0->xx_ent_wiki_sm==2.2.0) (3.1.0)\n",
      "Building wheels for collected packages: xx-ent-wiki-sm\n",
      "  Building wheel for xx-ent-wiki-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for xx-ent-wiki-sm: filename=xx_ent_wiki_sm-2.2.0-cp36-none-any.whl size=3732135 sha256=d16046f97687f1c2eb7a676a65bfb4f0c417bda6e0ebb6e678b35708d9f9ddd9\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-zgx_ijwa/wheels/61/ed/d5/02efb1ca98ca2550f28e24fd3931855512448672cfdad7d2c9\n",
      "Successfully built xx-ent-wiki-sm\n",
      "Installing collected packages: xx-ent-wiki-sm\n",
      "Successfully installed xx-ent-wiki-sm-2.2.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('xx_ent_wiki_sm')\n",
      "Collecting texthero\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/5a/a9d33b799fe53011de79d140ad6d86c440a2da1ae8a7b24e851ee2f8bde8/texthero-1.0.9-py3-none-any.whl\n",
      "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from texthero) (2.2.4)\n",
      "Collecting unidecode>=1.1.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/42/d9edfed04228bacea2d824904cae367ee9efd05e6cce7ceaaedd0b0ad964/Unidecode-1.1.1-py2.py3-none-any.whl (238kB)\n",
      "\u001b[K     |████████████████████████████████| 245kB 5.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: wordcloud>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from texthero) (1.5.0)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from texthero) (0.22.2.post1)\n",
      "Requirement already satisfied: pandas>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from texthero) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from texthero) (1.18.5)\n",
      "Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.6/dist-packages (from texthero) (3.2.2)\n",
      "Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.6/dist-packages (from texthero) (4.41.1)\n",
      "Requirement already satisfied: plotly>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from texthero) (4.4.1)\n",
      "Collecting nltk>=3.3\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/75/ce35194d8e3022203cca0d2f896dbb88689f9b3fce8e9f9cff942913519d/nltk-3.5.zip (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 8.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: gensim>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from texthero) (3.6.0)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (2.23.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (3.0.2)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (0.4.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (1.0.2)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (0.7.0)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (1.0.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (49.1.0)\n",
      "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (7.4.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->texthero) (2.0.3)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud>=1.5.0->texthero) (7.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22->texthero) (0.16.0)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.22->texthero) (1.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.2->texthero) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=1.0.2->texthero) (2018.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->texthero) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=3.1.0->texthero) (2.4.7)\n",
      "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.6/dist-packages (from plotly>=4.2.0->texthero) (1.3.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from plotly>=4.2.0->texthero) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->texthero) (7.1.2)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->texthero) (2019.12.20)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim>=3.6.0->texthero) (2.1.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2020.6.20)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->texthero) (2.10)\n",
      "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (1.7.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.6.0->texthero) (1.14.20)\n",
      "Requirement already satisfied: boto in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim>=3.6.0->texthero) (2.49.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->texthero) (3.1.0)\n",
      "Requirement already satisfied: botocore<1.18.0,>=1.17.20 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.6.0->texthero) (1.17.20)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.6.0->texthero) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim>=3.6.0->texthero) (0.10.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.18.0,>=1.17.20->boto3->smart-open>=1.2.1->gensim>=3.6.0->texthero) (0.15.2)\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nltk: filename=nltk-3.5-cp36-none-any.whl size=1434676 sha256=056d184f0717dcbef4be58724295a80472265fe508b65aecdba08ef74f4b6a78\n",
      "  Stored in directory: /root/.cache/pip/wheels/ae/8c/3f/b1fe0ba04555b08b57ab52ab7f86023639a526d8bc8d384306\n",
      "Successfully built nltk\n",
      "Installing collected packages: unidecode, nltk, texthero\n",
      "  Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "Successfully installed nltk-3.5 texthero-1.0.9 unidecode-1.1.1\n",
      "Collecting contractions\n",
      "  Downloading https://files.pythonhosted.org/packages/00/92/a05b76a692ac08d470ae5c23873cf1c9a041532f1ee065e74b374f218306/contractions-0.0.25-py2.py3-none-any.whl\n",
      "Collecting textsearch\n",
      "  Downloading https://files.pythonhosted.org/packages/42/a8/03407021f9555043de5492a2bd7a35c56cc03c2510092b5ec018cae1bbf1/textsearch-0.0.17-py2.py3-none-any.whl\n",
      "Requirement already satisfied: Unidecode in /usr/local/lib/python3.6/dist-packages (from textsearch->contractions) (1.1.1)\n",
      "Collecting pyahocorasick\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f4/9f/f0d8e8850e12829eea2e778f1c90e3c53a9a799b7f412082a5d21cd19ae1/pyahocorasick-1.4.0.tar.gz (312kB)\n",
      "\u001b[K     |████████████████████████████████| 317kB 4.4MB/s \n",
      "\u001b[?25hBuilding wheels for collected packages: pyahocorasick\n",
      "  Building wheel for pyahocorasick (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyahocorasick: filename=pyahocorasick-1.4.0-cp36-cp36m-linux_x86_64.whl size=81698 sha256=1a3e4a13e830bcbc328beff11dfd99cfe708daad873f8a583ad51f4a876aa98d\n",
      "  Stored in directory: /root/.cache/pip/wheels/0a/90/61/87a55f5b459792fbb2b7ba6b31721b06ff5cf6bde541b40994\n",
      "Successfully built pyahocorasick\n",
      "Installing collected packages: pyahocorasick, textsearch, contractions\n",
      "Successfully installed contractions-0.0.25 pyahocorasick-1.4.0 textsearch-0.0.17\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n",
    "!pip install demoji\n",
    "!pip install spacy_cld\n",
    "!pip install autocorrect\n",
    "!pip install pandarallel\n",
    "!python -m spacy download xx_ent_wiki_sm\n",
    "!pip install texthero\n",
    "!pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 62744,
     "status": "ok",
     "timestamp": 1594977466859,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "TixUOwjl4gWB",
    "outputId": "cd4d8642-feaa-43c0-b753-f9e1342023c7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4554,
     "status": "ok",
     "timestamp": 1594977471444,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "liShOX9R4gWD",
    "outputId": "5f36ae06-5d6e-4fad-e442-ea0b8f39dd77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 2 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n",
      "Downloading emoji data ...\n",
      "... OK (Got response in 0.10 seconds)\n",
      "Writing emoji data to /root/.demoji/codes.json ...\n",
      "... OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'+', \"'\", '_', '`', '*', '\\\\', '&', '[', '?', '\"', '>', '~', '{', '#', '-', '$', '/', '<', ':', '@', '%', '|', '}', '^', '(', '!', '.', ']', ')', '=', ';', ','}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "\n",
    "import spacy\n",
    "from spacy_cld import LanguageDetector\n",
    "import xx_ent_wiki_sm\n",
    "\n",
    "from autocorrect import Speller\n",
    "\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "import emoji\n",
    "import demoji\n",
    "demoji.download_codes()\n",
    "\n",
    "import texthero as hero\n",
    "import contractions\n",
    "\n",
    "import time\n",
    "\n",
    "import string\n",
    "\n",
    "punct = set(string.punctuation)\n",
    "print(punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 644,
     "status": "ok",
     "timestamp": 1594642235701,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "lKNUZIi-b9AM"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "apm8yMrl4gWG"
   },
   "source": [
    "### 1.2 Chargement et visualisation des données<a class=\"anchor\" id=\"1.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>On commence par charger 3 jeux de données dans 3 dataframes. Ces 3 jeux correspondent à :\n",
    "<ul>\n",
    "    <li>train : jeu d'entrainement dans lequel on ne va conserver que 2 informations : les colonnes \"comment_text\" correspondant aux commentaires et \"toxic\" qui est un booléen et qui correspond à notre donnée à prédire. Les autres informations permettant de catégoriser le texte ne sont pas prises en compte comme le fait qu'il s'agisse d'une insulte ou d'un commentaire obscène. A noter que dans ce jeu d'entrainement les commentaires sont en anglais.</li>\n",
    "    <li>valid : jeu de validation. Ce jeu de données permettra de valider le modèle entrainé. Les commentaires dans ce jeu de données sont multilingues.</li>\n",
    "    <li>test : jeu de test utilisé pour la soumission dans le cadre du concours. L'idée est donc de venir prédire la toxicité des commentaires contenus dans ce fichier à partir du modèle entrainé précédemment.</li>\n",
    "</ul>\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17328,
     "status": "ok",
     "timestamp": 1594630482198,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "NrP-7D7I4gWG",
    "outputId": "733a18bf-a65c-49e7-8df8-7e8486d97e56"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  ... lang\n",
       "0  0000997932d777bf  ...   en\n",
       "1  000103f0d9cfb60f  ...   en\n",
       "2  000113f07ec002fd  ...   en\n",
       "3  0001b41b1c6bb37e  ...   en\n",
       "4  0001d958c54c6e35  ...   en\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(223549, 4)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Este usuario ni siquiera llega al rango de    hereje   . Por lo tanto debería ser quemado en la barbacoa para purificar su alma y nuestro aparato digestivo mediante su ingestión.    Skipe linkin 22px   Honor, valor, leltad.      17:48 13 mar 2008 (UTC)</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Il testo di questa voce pare esser scopiazzato direttamente da qui. Immagino possano esserci problemi di copyright, nel fare cio .</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Vale. Sólo expongo mi pasado. Todo tiempo pasado fue mejor, ni mucho menos, yo no quisiera retroceder 31 años a nivel particular. Las volveria a pasar putas.Fernando</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bu maddenin alt başlığı olarak  uluslararası ilişkiler  ile konuyu sürdürmek ile ilgili tereddütlerim var.Önerim siyaset bilimi ana başlığından sonra siyasal yaşam ve toplum, siyasal güç, siyasal çatışma, siyasal gruplar, çağdaş ideolojiler, din, siyasal değişme, kamuoyu, propaganda ve siyasal katılma temelinde çoğulcu siyasal sistemler.Bu alt başlıkların daha anlamlı olacağı kanaatindeyim.</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Belçika nın şehirlerinin yanında ilçe ve beldelerini yaparken sanırım Portekizi örnek alacaksın. Ben de uzak gelecekte(2-3 yıl) bu tip şeyler düşünüyorum. Tabii futbol maddelerinin hakkından geldikten sonra..    daha önce mesajlarınızı görmüştüm, hatta anon bölümünü bizzat kullanıyordum   sözünü anlamadım??  tanışmak bugüneymiş gibi bir şey eklemeyi düşündüm ama vazgeçtim. orayı da silmeyi unuttum. boşverin Kıdemli   +</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ... toxic\n",
       "0   0  ...     0\n",
       "1   1  ...     0\n",
       "2   2  ...     1\n",
       "3   3  ...     0\n",
       "4   4  ...     0\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(8000, 4)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Doctor Who adlı viki başlığına 12. doctor olarak bir viki yazarı kendi adını eklemiştir. Şahsen düzelttim. Onaylarsanız sevinirim. Occipital</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Вполне возможно, но я пока не вижу необходимости выделять материал в отдельную статью. Если про правосудие в СССР будет написано хотя бы килобайт 20-30 — тогда да, следует разделить. Пока же мы в итоге получим одну куцую статью Правосудие и другую не менее куцую статью Правосудие в СССР. Мне кажется, что этот вопрос вполне разумно решать на основе правил ВП:Размер статей? которые не предписывают разделения, пока размер статьи не достигнет хотя бы 50 тыс. знаков.</td>\n",
       "      <td>ru</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Quindi tu sei uno di quelli   conservativi  , che preferiscono non cancellare. Ok. Avresti lasciato anche   sfaccimma  ? Si? Ok. Contento te... io non approvo per nulla, ma non conto nemmeno nulla... Allora lo sai che faccio? Me ne frego! (Aborro il fascismo, ma quando ce vo , ce vo !) Elborgo (sms)</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Malesef gerçekleştirilmedi ancak şöyle bir şey vardı. Belki yararlanırsınız. İyi çalışmalar.    Kud      yaz     Teşekkür ederim. Abidenin maddesini de genişletmeyi düşünüyorum, ileride işime yarayacak bu. cobija  Kullandın mı bilmiyorum ama şunu ve şunu da ben iliştireyim. Belki kaynakçaları lazım olur )RapsarEfendim?  Yok mu artıran? ) . Kullandınız mı bilmiyorum ama kullanmadıysanız alttaki model, 3d, senaryo ve yerleştirme başlıklarını da incelemenizi tavsiye ederim.    Kud      yaz     Aynen ya, çok güzel bir kaynak ama çalışma sahiplerine attığım e-postaya bir cevap gelmedi. Oradaki çalışmaları kullanabilseydim güzel olacaktı. cobija</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>:Resim:Seldabagcan.jpg resminde kaynak sorunu    :Resim:Seldabagcan.jpg    resmini yüklediğiniz için teşekkürler. Ancak dosyanın tanım sayfasında içeriğin kimin tarafından yapıldığı hakkında ayrıntılı bilgi bulunmamaktadır, yani telif durumu açık değildir. Eğer dosyayı kendiniz yapmadıysanız, içeriğin sahibini belirtmelisiniz. Bir internet sitesinden elde ettiyseniz nereden aldığınızı net şekilde gösteren bir bağlantı veriniz. Diğer yüklediğiniz resimleri kontrol etmek istiyorsanız bu bağlantıyı tıklayın.    Kaynaksız ve lisanssız resimler hızlı silme kriterlerinde belirtildiği üzere işaretlendikten bir hafta sonra silinirler.    Telif hakları saklı olup adil kullanım politikasına uymayan resimler    48 saat sonra silinirler   . Sorularınız için Vikipedi:Medya telif soruları sayfasını kullanabilirsiniz. Teşekkürler.    Yabancı     msj    :Resim:Seldabagcan.jpg için adil kullanım gerekçesi          :Resim:Seldabagcan.jpg    resmini yüklediğiniz için teşekkürler. Yüklediğiniz resim adil kullanım politikasına uymak zorundadır ancak bu politikaya nasıl uyduğunu gösteren bir açıklama veya gerekçe bulunmamaktadır. Resim tanım sayfasına, kullanıldığı her madde için ayrı ayrı olacak şekilde bir    adil kullanım gerekçesi    yazmalısınız. Yüklediğiniz diğer resimleri kontrol etmek için bu bağlantıyı tıklayınız.    Gerekçesi eksik olan adil kullanım resimleri hızlı silme kriterleri gereğince bir hafta sonra silinirler.    Sorularınız için Vikipedi:Medya telif soruları sayfasını kullanabilirsiniz. Teşekkürler.    Yabancı     msj</td>\n",
       "      <td>tr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ... lang\n",
       "0   0  ...   tr\n",
       "1   1  ...   ru\n",
       "2   2  ...   it\n",
       "3   3  ...   tr\n",
       "4   4  ...   tr\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(63812, 3)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = pd.read_csv('../input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')\n",
    "valid = pd.read_csv('../input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\n",
    "test = pd.read_csv('../input/jigsaw-multilingual-toxic-comment-classification/test.csv')\n",
    "\n",
    "train.drop(['severe_toxic','obscene','threat','insult','identity_hate'],axis=1,inplace=True)\n",
    "\n",
    "train['lang'] = 'en'\n",
    "\n",
    "#train\n",
    "display(train.head())\n",
    "display(train.shape)\n",
    "\n",
    "#valid\n",
    "display(valid.head())\n",
    "display(valid.shape)\n",
    "\n",
    "#test\n",
    "display(test.head())\n",
    "display(test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Vérifions la ventilation des données par rapport à la variable \"toxic\". On constate que seul 10% des data sont considérées toxiques dans le jeu d'entrainement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8878,
     "status": "ok",
     "timestamp": 1594630494679,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "2QLhy83i4gWJ",
    "outputId": "9c308efd-015f-4111-84a9-ac0c333b8d2e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    202165\n",
       "1     21384\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    6770\n",
       "1    1230\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(train.toxic.value_counts())\n",
    "display(valid.toxic.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLUmZw9e4gWM"
   },
   "source": [
    "### 1.3 Traitement de nettoyage<a class=\"anchor\" id=\"1.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sjNkLAqXimuU"
   },
   "source": [
    "#### 1.3.1 Gestion des emojis<a class=\"anchor\" id=\"1.3.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>La première étape du nettoyage va concerner les emojis. Je vais utiliser 2 librairies dans ce cadre : demoji et emoji. La librairie demoji va me permettre de lister de manière unique tous les emojis présents dans la colonne \"comment_text\" de notre jeu de données. La librairie emoji, quant à elle va être utilisée pour convertir les emojis en texte. Ce texte, sera aussi nettoyé avec la suppression des caractères \"_\". Ceci va occasionner des doubles espaces qui seront supprimés dans l'étape suivante de notre nettoyage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25592,
     "status": "ok",
     "timestamp": 1594630523777,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "WUAYJa97isSs"
   },
   "outputs": [],
   "source": [
    "other_characters = []\n",
    "for s in train['comment_text'].fillna('').astype(str):\n",
    "    for c in s:\n",
    "        if c.isdigit() or c.isalpha() or c.isalnum() or c.isspace() or c in punct:\n",
    "            continue\n",
    "        other_characters.append(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11562,
     "status": "ok",
     "timestamp": 1594630523785,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "mk3csKiji-Ba",
    "outputId": "ed46b7ea-9054-457f-d05d-ea83cfffa342"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'©': 'copyright',\n",
       " '®': 'registered',\n",
       " '‼': 'double exclamation mark',\n",
       " '™': 'trade mark',\n",
       " '↔': 'left-right arrow',\n",
       " '↕': 'up-down arrow',\n",
       " '↗': 'up-right arrow',\n",
       " '↘': 'down-right arrow',\n",
       " '↙': 'down-left arrow',\n",
       " 'Ⓜ': 'circled M',\n",
       " '▪': 'black small square',\n",
       " '▫': 'white small square',\n",
       " '▶': 'play button',\n",
       " '◀': 'reverse button',\n",
       " '◾': 'black medium-small square',\n",
       " '☀': 'sun',\n",
       " '☁': 'cloud',\n",
       " '☂': 'umbrella',\n",
       " '☃': 'snowman',\n",
       " '☄': 'comet',\n",
       " '☎': 'telephone',\n",
       " '☑': 'check box with check',\n",
       " '☘': 'shamrock',\n",
       " '☝': 'index pointing up',\n",
       " '☠': 'skull and crossbones',\n",
       " '☢': 'radioactive',\n",
       " '☣': 'biohazard',\n",
       " '☪': 'star and crescent',\n",
       " '☮': 'peace symbol',\n",
       " '☯': 'yin yang',\n",
       " '☸': 'wheel of dharma',\n",
       " '☺': 'smiling face',\n",
       " '♀': 'female sign',\n",
       " '♂': 'male sign',\n",
       " '♑': 'Capricorn',\n",
       " '♟': 'chess pawn',\n",
       " '♠': 'spade suit',\n",
       " '♣': 'club suit',\n",
       " '♥': 'heart suit',\n",
       " '♦': 'diamond suit',\n",
       " '♨': 'hot springs',\n",
       " '⚔': 'crossed swords',\n",
       " '✈': 'airplane',\n",
       " '✉': 'envelope',\n",
       " '✋🏼': 'raised hand: medium-light skin tone',\n",
       " '✌': 'victory hand',\n",
       " '✍': 'writing hand',\n",
       " '✒': 'black nib',\n",
       " '✔': 'check mark',\n",
       " '✝': 'latin cross',\n",
       " '✡': 'star of David',\n",
       " '❄': 'snowflake',\n",
       " '❣': 'heart exclamation',\n",
       " '❤': 'red heart',\n",
       " '⬅': 'left arrow',\n",
       " '🍁': 'maple leaf',\n",
       " '🍌': 'banana',\n",
       " '🎄': 'Christmas tree',\n",
       " '🎊': 'confetti ball',\n",
       " '🎤': 'microphone',\n",
       " '🐣': 'hatching chick',\n",
       " '👍': 'thumbs up',\n",
       " '👴': 'old man',\n",
       " '💜': 'purple heart',\n",
       " '💩': 'pile of poo',\n",
       " '💬': 'speech balloon',\n",
       " '📞': 'telephone receiver',\n",
       " '📧': 'e-mail',\n",
       " '🖖': 'vulcan salute',\n",
       " '🗽': 'Statue of Liberty',\n",
       " '😀': 'grinning face',\n",
       " '😂': 'face with tears of joy',\n",
       " '😃': 'grinning face with big eyes',\n",
       " '😄': 'grinning face with smiling eyes',\n",
       " '😅': 'grinning face with sweat',\n",
       " '😉': 'winking face',\n",
       " '😊': 'smiling face with smiling eyes',\n",
       " '😏': 'smirking face',\n",
       " '😓': 'downcast face with sweat',\n",
       " '😔': 'pensive face',\n",
       " '😜': 'winking face with tongue',\n",
       " '😠': 'angry face',\n",
       " '😢': 'crying face',\n",
       " '🙈': 'see-no-evil monkey',\n",
       " '🙉': 'hear-no-evil monkey',\n",
       " '🙊': 'speak-no-evil monkey'}"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demoji.findall(''.join(other_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8297,
     "status": "ok",
     "timestamp": 1594630523794,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "MkCm84ZkHlyB"
   },
   "outputs": [],
   "source": [
    "def convert_emoji(text):\n",
    "  text_clean = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "  text_clean = text_clean.replace(\"_\", \" \")\n",
    "  return text_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ci-dessous un exemple du résultat de la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 780,
     "status": "ok",
     "timestamp": 1594630524659,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "NgPxBVyCIayV"
   },
   "outputs": [],
   "source": [
    "text = \"game is on 🔥😂\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1316,
     "status": "ok",
     "timestamp": 1594630525269,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "7ohBcxN9MIz-",
    "outputId": "f58c6195-90f1-4d2e-ac4f-2f4c73d80327"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'game is on  fire  face with tears of joy '"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_emoji(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 388852,
     "status": "ok",
     "timestamp": 1594631060758,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "ZLG1gC2DInPC",
    "outputId": "6509b17a-38e8-4414-cfa2-ad4acd8c9a55"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223549/223549 [06:28<00:00, 575.62it/s]\n"
     ]
    }
   ],
   "source": [
    "train['comment_text'] = train.progress_apply(lambda x: convert_emoji(x['comment_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 303
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 539,
     "status": "ok",
     "timestamp": 1594631089051,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "GwgsdWQ5KDf7",
    "outputId": "e43ac1aa-6ac8-4c48-ea23-d5a55913cd74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lang</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good article nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  ... lang\n",
       "0  0000997932d777bf  ...   en\n",
       "1  000103f0d9cfb60f  ...   en\n",
       "2  000113f07ec002fd  ...   en\n",
       "3  0001b41b1c6bb37e  ...   en\n",
       "4  0001d958c54c6e35  ...   en\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24109,
     "status": "ok",
     "timestamp": 1594632224663,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "-CTwSqkVe9Jm",
    "outputId": "d7aa563f-869a-4532-aa55-011830d3faf3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:13<00:00, 593.69it/s]\n"
     ]
    }
   ],
   "source": [
    "valid['comment_text'] = valid.progress_apply(lambda x: convert_emoji(x['comment_text']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 123377,
     "status": "ok",
     "timestamp": 1594632351317,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "VwIjqD8dfGo2",
    "outputId": "f9dbc622-f5cd-4800-86ef-a9055484d513"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 63812/63812 [01:57<00:00, 543.57it/s]\n"
     ]
    }
   ],
   "source": [
    "test['content'] = test.progress_apply(lambda x: convert_emoji(x['content']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3C7BPIduY9kI"
   },
   "source": [
    "#### 1.3.2 Suppression des digits et autres caractères indésirables<a class=\"anchor\" id=\"1.3.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>L'étape suivante consiste à supprimer tout caractère indésirable dans la colonne \"comment_text\" du jeu de données. Pour cela, je vais utiliser la librairie <b>texthero</b>. Cette librairie est très intéressante car elle permet, de manière très rapide, d'effectuer plusieurs tâches de nettoyage simultanément. Pour cela, il suffira de définir la tâche à effectuer dans le pipeline. Ici, je vais supprimer les digits, les éventuels diacritiques (accents, tremas, retour charriot...), les doubles espaces, les urls et les tags html. Le résultat est ensuite inséré dans une nouvelle colonne nommée \"comment_text_clean\". On peut voir ci-dessous le résultat obtenu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 13469,
     "status": "ok",
     "timestamp": 1594631109846,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "b076G2kMZL8p"
   },
   "outputs": [],
   "source": [
    "train['comment_text_clean'] = (\n",
    "    train['comment_text']\n",
    "    .pipe(hero.remove_digits)\n",
    "    .pipe(hero.remove_diacritics)\n",
    "    .pipe(hero.remove_whitespace)\n",
    "    .pipe(hero.remove_urls)\n",
    "    .pipe(hero.remove_html_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10988,
     "status": "ok",
     "timestamp": 1594631109849,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "QFsyCJwzbshy",
    "outputId": "2a0c493b-2942-4414-ef77-91d03a62b89a",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lang</th>\n",
       "      <th>comment_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now. . . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks. (talk) : , January , (UTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good article nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>\" More I can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\" -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know. There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good article nominations#Transport \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           comment_text_clean\n",
       "0  0000997932d777bf  ...                                                                                                                                                                                                                                                                                                                                                                           Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now. . . .\n",
       "1  000103f0d9cfb60f  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        D'aww! He matches this background colour I'm seemingly stuck with. Thanks. (talk) : , January , (UTC)\n",
       "2  000113f07ec002fd  ...                                                                                                                                                                                                                                                                                                                                                                                                    Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
       "3  0001b41b1c6bb37e  ...  \" More I can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\" -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know. There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good article nominations#Transport \"\n",
       "4  0001d958c54c6e35  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          You, sir, are my hero. Any chance you remember what page that's on?\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ce même nettoyage est réalisé sur les jeux de validation et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 862,
     "status": "ok",
     "timestamp": 1594632527941,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "M7_-OOlxfPfH"
   },
   "outputs": [],
   "source": [
    "valid['comment_text_clean'] = (\n",
    "    valid['comment_text']\n",
    "    .pipe(hero.remove_digits)\n",
    "    .pipe(hero.remove_whitespace)\n",
    "    .pipe(hero.remove_urls)\n",
    "    .pipe(hero.remove_html_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 779,
     "status": "ok",
     "timestamp": 1594632530463,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "Ne9wDA-Pfx5J",
    "outputId": "a64c8a51-5d0e-4b0c-d992-da1edb36ad7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>lang</th>\n",
       "      <th>toxic</th>\n",
       "      <th>comment_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Este usuario ni siquiera llega al rango de    hereje   . Por lo tanto debería ser quemado en la barbacoa para purificar su alma y nuestro aparato digestivo mediante su ingestión.    Skipe linkin 22px   Honor, valor, leltad.      17:48 13 mar 2008 (UTC)</td>\n",
       "      <td>es</td>\n",
       "      <td>0</td>\n",
       "      <td>Este usuario ni siquiera llega al rango de hereje . Por lo tanto debería ser quemado en la barbacoa para purificar su alma y nuestro aparato digestivo mediante su ingestión. Skipe linkin 22px Honor, valor, leltad. : mar (UTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Il testo di questa voce pare esser scopiazzato direttamente da qui. Immagino possano esserci problemi di copyright, nel fare cio .</td>\n",
       "      <td>it</td>\n",
       "      <td>0</td>\n",
       "      <td>Il testo di questa voce pare esser scopiazzato direttamente da qui. Immagino possano esserci problemi di copyright, nel fare cio .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Vale. Sólo expongo mi pasado. Todo tiempo pasado fue mejor, ni mucho menos, yo no quisiera retroceder 31 años a nivel particular. Las volveria a pasar putas.Fernando</td>\n",
       "      <td>es</td>\n",
       "      <td>1</td>\n",
       "      <td>Vale. Sólo expongo mi pasado. Todo tiempo pasado fue mejor, ni mucho menos, yo no quisiera retroceder años a nivel particular. Las volveria a pasar putas.Fernando</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Bu maddenin alt başlığı olarak  uluslararası ilişkiler  ile konuyu sürdürmek ile ilgili tereddütlerim var.Önerim siyaset bilimi ana başlığından sonra siyasal yaşam ve toplum, siyasal güç, siyasal çatışma, siyasal gruplar, çağdaş ideolojiler, din, siyasal değişme, kamuoyu, propaganda ve siyasal katılma temelinde çoğulcu siyasal sistemler.Bu alt başlıkların daha anlamlı olacağı kanaatindeyim.</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>Bu maddenin alt başlığı olarak uluslararası ilişkiler ile konuyu sürdürmek ile ilgili tereddütlerim var.Önerim siyaset bilimi ana başlığından sonra siyasal yaşam ve toplum, siyasal güç, siyasal çatışma, siyasal gruplar, çağdaş ideolojiler, din, siyasal değişme, kamuoyu, propaganda ve siyasal katılma temelinde çoğulcu siyasal sistemler.Bu alt başlıkların daha anlamlı olacağı kanaatindeyim.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Belçika nın şehirlerinin yanında ilçe ve beldelerini yaparken sanırım Portekizi örnek alacaksın. Ben de uzak gelecekte(2-3 yıl) bu tip şeyler düşünüyorum. Tabii futbol maddelerinin hakkından geldikten sonra..    daha önce mesajlarınızı görmüştüm, hatta anon bölümünü bizzat kullanıyordum   sözünü anlamadım??  tanışmak bugüneymiş gibi bir şey eklemeyi düşündüm ama vazgeçtim. orayı da silmeyi unuttum. boşverin Kıdemli   +</td>\n",
       "      <td>tr</td>\n",
       "      <td>0</td>\n",
       "      <td>Belçika nın şehirlerinin yanında ilçe ve beldelerini yaparken sanırım Portekizi örnek alacaksın. Ben de uzak gelecekte( - yıl) bu tip şeyler düşünüyorum. Tabii futbol maddelerinin hakkından geldikten sonra.. daha önce mesajlarınızı görmüştüm, hatta anon bölümünü bizzat kullanıyordum sözünü anlamadım?? tanışmak bugüneymiş gibi bir şey eklemeyi düşündüm ama vazgeçtim. orayı da silmeyi unuttum. boşverin Kıdemli +</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ...                                                                                                                                                                                                                                                                                                                                                                                                             comment_text_clean\n",
       "0   0  ...                                                                                                                                                                                              Este usuario ni siquiera llega al rango de hereje . Por lo tanto debería ser quemado en la barbacoa para purificar su alma y nuestro aparato digestivo mediante su ingestión. Skipe linkin 22px Honor, valor, leltad. : mar (UTC)\n",
       "1   1  ...                                                                                                                                                                                                                                                                                             Il testo di questa voce pare esser scopiazzato direttamente da qui. Immagino possano esserci problemi di copyright, nel fare cio .\n",
       "2   2  ...                                                                                                                                                                                                                                                             Vale. Sólo expongo mi pasado. Todo tiempo pasado fue mejor, ni mucho menos, yo no quisiera retroceder años a nivel particular. Las volveria a pasar putas.Fernando\n",
       "3   3  ...                        Bu maddenin alt başlığı olarak uluslararası ilişkiler ile konuyu sürdürmek ile ilgili tereddütlerim var.Önerim siyaset bilimi ana başlığından sonra siyasal yaşam ve toplum, siyasal güç, siyasal çatışma, siyasal gruplar, çağdaş ideolojiler, din, siyasal değişme, kamuoyu, propaganda ve siyasal katılma temelinde çoğulcu siyasal sistemler.Bu alt başlıkların daha anlamlı olacağı kanaatindeyim.\n",
       "4   4  ...  Belçika nın şehirlerinin yanında ilçe ve beldelerini yaparken sanırım Portekizi örnek alacaksın. Ben de uzak gelecekte( - yıl) bu tip şeyler düşünüyorum. Tabii futbol maddelerinin hakkından geldikten sonra.. daha önce mesajlarınızı görmüştüm, hatta anon bölümünü bizzat kullanıyordum sözünü anlamadım?? tanışmak bugüneymiş gibi bir şey eklemeyi düşündüm ama vazgeçtim. orayı da silmeyi unuttum. boşverin Kıdemli +\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3636,
     "status": "ok",
     "timestamp": 1594632540704,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "kYtWhyVbfSEH"
   },
   "outputs": [],
   "source": [
    "test['content_clean'] = (\n",
    "    test['content']\n",
    "    .pipe(hero.remove_digits)\n",
    "    .pipe(hero.remove_whitespace)\n",
    "    .pipe(hero.remove_urls)\n",
    "    .pipe(hero.remove_html_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 561,
     "status": "ok",
     "timestamp": 1594632542241,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "yMEKHzEff2QW",
    "outputId": "d72c9c77-f38d-4279-f5cd-cb65c7417af7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>content</th>\n",
       "      <th>lang</th>\n",
       "      <th>content_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Doctor Who adlı viki başlığına 12. doctor olarak bir viki yazarı kendi adını eklemiştir. Şahsen düzelttim. Onaylarsanız sevinirim. Occipital</td>\n",
       "      <td>tr</td>\n",
       "      <td>Doctor Who adlı viki başlığına . doctor olarak bir viki yazarı kendi adını eklemiştir. Şahsen düzelttim. Onaylarsanız sevinirim. Occipital</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Вполне возможно, но я пока не вижу необходимости выделять материал в отдельную статью. Если про правосудие в СССР будет написано хотя бы килобайт 20-30 — тогда да, следует разделить. Пока же мы в итоге получим одну куцую статью Правосудие и другую не менее куцую статью Правосудие в СССР. Мне кажется, что этот вопрос вполне разумно решать на основе правил ВП:Размер статей? которые не предписывают разделения, пока размер статьи не достигнет хотя бы 50 тыс. знаков.</td>\n",
       "      <td>ru</td>\n",
       "      <td>Вполне возможно, но я пока не вижу необходимости выделять материал в отдельную статью. Если про правосудие в СССР будет написано хотя бы килобайт - — тогда да, следует разделить. Пока же мы в итоге получим одну куцую статью Правосудие и другую не менее куцую статью Правосудие в СССР. Мне кажется, что этот вопрос вполне разумно решать на основе правил ВП:Размер статей? которые не предписывают разделения, пока размер статьи не достигнет хотя бы тыс. знаков.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Quindi tu sei uno di quelli   conservativi  , che preferiscono non cancellare. Ok. Avresti lasciato anche   sfaccimma  ? Si? Ok. Contento te... io non approvo per nulla, ma non conto nemmeno nulla... Allora lo sai che faccio? Me ne frego! (Aborro il fascismo, ma quando ce vo , ce vo !) Elborgo (sms)</td>\n",
       "      <td>it</td>\n",
       "      <td>Quindi tu sei uno di quelli conservativi , che preferiscono non cancellare. Ok. Avresti lasciato anche sfaccimma ? Si? Ok. Contento te... io non approvo per nulla, ma non conto nemmeno nulla... Allora lo sai che faccio? Me ne frego! (Aborro il fascismo, ma quando ce vo , ce vo !) Elborgo (sms)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Malesef gerçekleştirilmedi ancak şöyle bir şey vardı. Belki yararlanırsınız. İyi çalışmalar.    Kud      yaz     Teşekkür ederim. Abidenin maddesini de genişletmeyi düşünüyorum, ileride işime yarayacak bu. cobija  Kullandın mı bilmiyorum ama şunu ve şunu da ben iliştireyim. Belki kaynakçaları lazım olur )RapsarEfendim?  Yok mu artıran? ) . Kullandınız mı bilmiyorum ama kullanmadıysanız alttaki model, 3d, senaryo ve yerleştirme başlıklarını da incelemenizi tavsiye ederim.    Kud      yaz     Aynen ya, çok güzel bir kaynak ama çalışma sahiplerine attığım e-postaya bir cevap gelmedi. Oradaki çalışmaları kullanabilseydim güzel olacaktı. cobija</td>\n",
       "      <td>tr</td>\n",
       "      <td>Malesef gerçekleştirilmedi ancak şöyle bir şey vardı. Belki yararlanırsınız. İyi çalışmalar. Kud yaz Teşekkür ederim. Abidenin maddesini de genişletmeyi düşünüyorum, ileride işime yarayacak bu. cobija Kullandın mı bilmiyorum ama şunu ve şunu da ben iliştireyim. Belki kaynakçaları lazım olur )RapsarEfendim? Yok mu artıran? ) . Kullandınız mı bilmiyorum ama kullanmadıysanız alttaki model, 3d, senaryo ve yerleştirme başlıklarını da incelemenizi tavsiye ederim. Kud yaz Aynen ya, çok güzel bir kaynak ama çalışma sahiplerine attığım e-postaya bir cevap gelmedi. Oradaki çalışmaları kullanabilseydim güzel olacaktı. cobija</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>:Resim:Seldabagcan.jpg resminde kaynak sorunu    :Resim:Seldabagcan.jpg    resmini yüklediğiniz için teşekkürler. Ancak dosyanın tanım sayfasında içeriğin kimin tarafından yapıldığı hakkında ayrıntılı bilgi bulunmamaktadır, yani telif durumu açık değildir. Eğer dosyayı kendiniz yapmadıysanız, içeriğin sahibini belirtmelisiniz. Bir internet sitesinden elde ettiyseniz nereden aldığınızı net şekilde gösteren bir bağlantı veriniz. Diğer yüklediğiniz resimleri kontrol etmek istiyorsanız bu bağlantıyı tıklayın.    Kaynaksız ve lisanssız resimler hızlı silme kriterlerinde belirtildiği üzere işaretlendikten bir hafta sonra silinirler.    Telif hakları saklı olup adil kullanım politikasına uymayan resimler    48 saat sonra silinirler   . Sorularınız için Vikipedi:Medya telif soruları sayfasını kullanabilirsiniz. Teşekkürler.    Yabancı     msj    :Resim:Seldabagcan.jpg için adil kullanım gerekçesi          :Resim:Seldabagcan.jpg    resmini yüklediğiniz için teşekkürler. Yüklediğiniz resim adil kullanım politikasına uymak zorundadır ancak bu politikaya nasıl uyduğunu gösteren bir açıklama veya gerekçe bulunmamaktadır. Resim tanım sayfasına, kullanıldığı her madde için ayrı ayrı olacak şekilde bir    adil kullanım gerekçesi    yazmalısınız. Yüklediğiniz diğer resimleri kontrol etmek için bu bağlantıyı tıklayınız.    Gerekçesi eksik olan adil kullanım resimleri hızlı silme kriterleri gereğince bir hafta sonra silinirler.    Sorularınız için Vikipedi:Medya telif soruları sayfasını kullanabilirsiniz. Teşekkürler.    Yabancı     msj</td>\n",
       "      <td>tr</td>\n",
       "      <td>:Resim:Seldabagcan.jpg resminde kaynak sorunu :Resim:Seldabagcan.jpg resmini yüklediğiniz için teşekkürler. Ancak dosyanın tanım sayfasında içeriğin kimin tarafından yapıldığı hakkında ayrıntılı bilgi bulunmamaktadır, yani telif durumu açık değildir. Eğer dosyayı kendiniz yapmadıysanız, içeriğin sahibini belirtmelisiniz. Bir internet sitesinden elde ettiyseniz nereden aldığınızı net şekilde gösteren bir bağlantı veriniz. Diğer yüklediğiniz resimleri kontrol etmek istiyorsanız bu bağlantıyı tıklayın. Kaynaksız ve lisanssız resimler hızlı silme kriterlerinde belirtildiği üzere işaretlendikten bir hafta sonra silinirler. Telif hakları saklı olup adil kullanım politikasına uymayan resimler saat sonra silinirler . Sorularınız için Vikipedi:Medya telif soruları sayfasını kullanabilirsiniz. Teşekkürler. Yabancı msj :Resim:Seldabagcan.jpg için adil kullanım gerekçesi :Resim:Seldabagcan.jpg resmini yüklediğiniz için teşekkürler. Yüklediğiniz resim adil kullanım politikasına uymak zorundadır ancak bu politikaya nasıl uyduğunu gösteren bir açıklama veya gerekçe bulunmamaktadır. Resim tanım sayfasına, kullanıldığı her madde için ayrı ayrı olacak şekilde bir adil kullanım gerekçesi yazmalısınız. Yüklediğiniz diğer resimleri kontrol etmek için bu bağlantıyı tıklayınız. Gerekçesi eksik olan adil kullanım resimleri hızlı silme kriterleri gereğince bir hafta sonra silinirler. Sorularınız için Vikipedi:Medya telif soruları sayfasını kullanabilirsiniz. Teşekkürler. Yabancı msj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               content_clean\n",
       "0   0  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Doctor Who adlı viki başlığına . doctor olarak bir viki yazarı kendi adını eklemiştir. Şahsen düzelttim. Onaylarsanız sevinirim. Occipital\n",
       "1   1  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 Вполне возможно, но я пока не вижу необходимости выделять материал в отдельную статью. Если про правосудие в СССР будет написано хотя бы килобайт - — тогда да, следует разделить. Пока же мы в итоге получим одну куцую статью Правосудие и другую не менее куцую статью Правосудие в СССР. Мне кажется, что этот вопрос вполне разумно решать на основе правил ВП:Размер статей? которые не предписывают разделения, пока размер статьи не достигнет хотя бы тыс. знаков.\n",
       "2   2  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Quindi tu sei uno di quelli conservativi , che preferiscono non cancellare. Ok. Avresti lasciato anche sfaccimma ? Si? Ok. Contento te... io non approvo per nulla, ma non conto nemmeno nulla... Allora lo sai che faccio? Me ne frego! (Aborro il fascismo, ma quando ce vo , ce vo !) Elborgo (sms)\n",
       "3   3  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Malesef gerçekleştirilmedi ancak şöyle bir şey vardı. Belki yararlanırsınız. İyi çalışmalar. Kud yaz Teşekkür ederim. Abidenin maddesini de genişletmeyi düşünüyorum, ileride işime yarayacak bu. cobija Kullandın mı bilmiyorum ama şunu ve şunu da ben iliştireyim. Belki kaynakçaları lazım olur )RapsarEfendim? Yok mu artıran? ) . Kullandınız mı bilmiyorum ama kullanmadıysanız alttaki model, 3d, senaryo ve yerleştirme başlıklarını da incelemenizi tavsiye ederim. Kud yaz Aynen ya, çok güzel bir kaynak ama çalışma sahiplerine attığım e-postaya bir cevap gelmedi. Oradaki çalışmaları kullanabilseydim güzel olacaktı. cobija\n",
       "4   4  ...  :Resim:Seldabagcan.jpg resminde kaynak sorunu :Resim:Seldabagcan.jpg resmini yüklediğiniz için teşekkürler. Ancak dosyanın tanım sayfasında içeriğin kimin tarafından yapıldığı hakkında ayrıntılı bilgi bulunmamaktadır, yani telif durumu açık değildir. Eğer dosyayı kendiniz yapmadıysanız, içeriğin sahibini belirtmelisiniz. Bir internet sitesinden elde ettiyseniz nereden aldığınızı net şekilde gösteren bir bağlantı veriniz. Diğer yüklediğiniz resimleri kontrol etmek istiyorsanız bu bağlantıyı tıklayın. Kaynaksız ve lisanssız resimler hızlı silme kriterlerinde belirtildiği üzere işaretlendikten bir hafta sonra silinirler. Telif hakları saklı olup adil kullanım politikasına uymayan resimler saat sonra silinirler . Sorularınız için Vikipedi:Medya telif soruları sayfasını kullanabilirsiniz. Teşekkürler. Yabancı msj :Resim:Seldabagcan.jpg için adil kullanım gerekçesi :Resim:Seldabagcan.jpg resmini yüklediğiniz için teşekkürler. Yüklediğiniz resim adil kullanım politikasına uymak zorundadır ancak bu politikaya nasıl uyduğunu gösteren bir açıklama veya gerekçe bulunmamaktadır. Resim tanım sayfasına, kullanıldığı her madde için ayrı ayrı olacak şekilde bir adil kullanım gerekçesi yazmalısınız. Yüklediğiniz diğer resimleri kontrol etmek için bu bağlantıyı tıklayınız. Gerekçesi eksik olan adil kullanım resimleri hızlı silme kriterleri gereğince bir hafta sonra silinirler. Sorularınız için Vikipedi:Medya telif soruları sayfasını kullanabilirsiniz. Teşekkürler. Yabancı msj\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "elBwCkOuc4Q-"
   },
   "source": [
    "#### 1.3.3 Suppression des contractions<a class=\"anchor\" id=\"1.3.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>L'intérêt ici est de remettre au \"propre\" certains termes anglais en supprimant les contractions (généralement produit sur des auxiliaires). Par exemple, \"you're\" est transformé en \"you are\". Cette transformation est appliquée sur la colonne \"comment_text_clean\" via l'utilisation de la librairie contractions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 638,
     "status": "ok",
     "timestamp": 1594631121837,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "Ow-WBPwFc9kK"
   },
   "outputs": [],
   "source": [
    "def remove_contractions(text):\n",
    "  text_clean = contractions.fix(str(text))\n",
    "  return text_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ci-dessous un exemple pour tester la fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 708,
     "status": "ok",
     "timestamp": 1594631123313,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "mK8QKnHFdcib",
    "outputId": "6b259526-aed6-4c08-c54b-334aab50cb71"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'I am ok'"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_contractions(\"I'm ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12353,
     "status": "ok",
     "timestamp": 1594631137744,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "tvHDy18ddcb4",
    "outputId": "81bb0fc5-9495-490b-f781-829fc71def49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223549/223549 [00:11<00:00, 19447.64it/s]\n"
     ]
    }
   ],
   "source": [
    "train['comment_text_clean'] = train.progress_apply(lambda x: remove_contractions(x['comment_text_clean']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1634,
     "status": "ok",
     "timestamp": 1594631137764,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "QwqgVQKtf5la",
    "outputId": "f1752eb2-1c3c-4b8c-e779-264056aa971f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lang</th>\n",
       "      <th>comment_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They were not vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please do not remove the template from the talk page since I am retired now. . . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>D'aww! He matches this background colour I am seemingly stuck with. Thanks. (talk) : , January , (UTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Hey man, I am really not trying to edit war. it is just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good article nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>\" More I can not make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\" -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know. There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. it is listed in the relevant form eg Wikipedia:Good article nominations#Transport \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that is on?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              comment_text_clean\n",
       "0  0000997932d777bf  ...                                                                                                                                                                                                                                                                                                                                                                           Explanation Why the edits made under my username Hardcore Metallica Fan were reverted? They were not vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please do not remove the template from the talk page since I am retired now. . . .\n",
       "1  000103f0d9cfb60f  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          D'aww! He matches this background colour I am seemingly stuck with. Thanks. (talk) : , January , (UTC)\n",
       "2  000113f07ec002fd  ...                                                                                                                                                                                                                                                                                                                                                                                                     Hey man, I am really not trying to edit war. it is just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
       "3  0001b41b1c6bb37e  ...  \" More I can not make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\" -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know. There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. it is listed in the relevant form eg Wikipedia:Good article nominations#Transport \"\n",
       "4  0001d958c54c6e35  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            You, sir, are my hero. Any chance you remember what page that is on?\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cHO25Rmj4gWf"
   },
   "source": [
    "#### 1.3.4 Gestion des fautes d'orthographe<a class=\"anchor\" id=\"1.3.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W_ws9zYKNw0C"
   },
   "source": [
    "Ici, je vais essayer de corriger dans la mesure du possible les fautes d'orthographe qui ont pu se glisser dans les commentaires. Je vais utiliser la librairie autocorrect en prenant en compte le paramère fast à True. Cette méthode permet de gagner beaucoup de temps de traitement mais peut dégrader un peu la qualité de la correction. Tout se fait uniquement sur les commentaires en anglais et sur la colonne \"comment_text_clean\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1344,
     "status": "ok",
     "timestamp": 1594631142106,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "nnV7fseysrJb"
   },
   "outputs": [],
   "source": [
    "check = Speller(lang='en', fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 725,
     "status": "ok",
     "timestamp": 1594631144562,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "jg_sRBCcssTP"
   },
   "outputs": [],
   "source": [
    "def make_corrections(text):\n",
    "  text_clean = check(text)\n",
    "  return text_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Testons la fonction sur un texte mal orthographié."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 688,
     "status": "ok",
     "timestamp": 1594631147223,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "GwJe8FYKs6RR",
    "outputId": "022ca580-e9ef-4ebc-cec5-531562db4ae3"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic": {
       "type": "string"
      },
      "text/plain": [
       "'It is very good !'"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_corrections(\"It is veiry goood !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 501523,
     "status": "ok",
     "timestamp": 1594632100407,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "2WLBhH7nBewG",
    "outputId": "8a380ce3-1256-4f17-af77-3c7e4bc84758"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223549/223549 [08:16<00:00, 450.41it/s]\n"
     ]
    }
   ],
   "source": [
    "train['comment_text_clean'] = train.progress_apply(lambda x: make_corrections(x['comment_text_clean']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15616,
     "status": "ok",
     "timestamp": 1594632127888,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "Ppa9TCtVeukV",
    "outputId": "48d9df43-b7fd-40cf-ae67-c30a82321b67"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lang</th>\n",
       "      <th>comment_text_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Explanation Why the edits made under my username Hardcore Metallic Fan were reverted? They were not vandalisms, just closure on some As after I voted at New York Polls FoC. And please do not remove the template from the talk page since I am retired now. . . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>D'www! He matches this background colour I am seemingly stuck with. Thanks. (talk) : , January , (UTC)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Hey man, I am really not trying to edit war. it is just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good article nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>\" More I can not make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\" -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know. There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. it is listed in the relevant form eg Wikipedia:Good article nominations#Transport \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that is on?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              comment_text_clean\n",
       "0  0000997932d777bf  ...                                                                                                                                                                                                                                                                                                                                                                             Explanation Why the edits made under my username Hardcore Metallic Fan were reverted? They were not vandalisms, just closure on some As after I voted at New York Polls FoC. And please do not remove the template from the talk page since I am retired now. . . .\n",
       "1  000103f0d9cfb60f  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          D'www! He matches this background colour I am seemingly stuck with. Thanks. (talk) : , January , (UTC)\n",
       "2  000113f07ec002fd  ...                                                                                                                                                                                                                                                                                                                                                                                                     Hey man, I am really not trying to edit war. it is just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
       "3  0001b41b1c6bb37e  ...  \" More I can not make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\" -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know. There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. it is listed in the relevant form eg Wikipedia:Good article nominations#Transport \"\n",
       "4  0001d958c54c6e35  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            You, sir, are my hero. Any chance you remember what page that is on?\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u2y0PtfX4gWM"
   },
   "source": [
    "#### 1.3.5 Détection de langues<a class=\"anchor\" id=\"1.3.5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Enfin, pour cette dernière étape, je vais essayer de détecter la langue des commentaires entrainés. Pour cela, j'utilise la librairie spacy et un dictionnaire multilingue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 11967,
     "status": "ok",
     "timestamp": 1594644059954,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "_nKvRXDY4gWN"
   },
   "outputs": [],
   "source": [
    "nlp = xx_ent_wiki_sm.load()\n",
    "language_detect = LanguageDetector()\n",
    "nlp.add_pipe(language_detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 485,
     "status": "ok",
     "timestamp": 1594644117816,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "WPjtNz7yAtk-"
   },
   "outputs": [],
   "source": [
    "def get_lang_score(text, lang):\n",
    "    try:\n",
    "        doc = nlp(str(text))\n",
    "        language_scores = doc._.language_scores\n",
    "        return language_scores.get(lang, 0)\n",
    "    except Exception:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1559143,
     "status": "ok",
     "timestamp": 1594645690617,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "i6ZoPKpdMfE7",
    "outputId": "076574c9-8ad6-4f31-9ce3-a6e01826020b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 223549/223549 [25:58<00:00, 143.44it/s]\n"
     ]
    }
   ],
   "source": [
    "train['lang_score'] = train.progress_apply(lambda x: get_lang_score(x['comment_text_clean'], x['lang']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 579,
     "status": "ok",
     "timestamp": 1594645851089,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "9aPe64qsM1pI",
    "outputId": "8c6971be-d590-479f-b112-1a23bc6cb735"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lang</th>\n",
       "      <th>comment_text_clean</th>\n",
       "      <th>lang_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>005de39c51ef844a</td>\n",
       "      <td>Azari or Azerbaijani? \\n\\nAzari-iranian,azerbaijani-turkic nation.</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Zari or Azerbaijani? Zari-iranian,azerbaijani-turkic nation.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>177</td>\n",
       "      <td>006ca45465868e64</td>\n",
       "      <td>86.29.244.57|86.29.244.57]] 04:21, 14 May 2007</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>. . . | . . . ]] : , May</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>006eaaaca322e12d</td>\n",
       "      <td>\") (ETA: John D. Haynes House. SarekOfVulcan (talk) \"</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>\") (TA: John D. Raynes House. SarekOfVulcan (talk) \"</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>281</td>\n",
       "      <td>00b211fa0c65d328</td>\n",
       "      <td>2005 (UTC)\\n\\n  15:59, 17 December</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>(UTC) : , December</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>702</td>\n",
       "      <td>01e82a7c3b00c42a</td>\n",
       "      <td>Valerie Poxleitner \\n\\nValeri Poxleitner, A.K.A. Lights. If</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Valerin Poxleitner Valerin Poxleitner, A.K.A. Lights. If</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223351</th>\n",
       "      <td>223351</td>\n",
       "      <td>ff2a0602fc19d1cc</td>\n",
       "      <td>== Madde == \\n\\n Bu madde yalan Olmuş !!!! \\n\\n Bu kapsamda, Türkiye’nin güvenlik kaygıları temel olarak \\n Terörizm, uzun menzilli füzeler ve kitle imha silahlarının yayılması, İrticai faaliyetler, Bölgesel çatışmalardan kaynaklanmaktadır.</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>== Made == Bu made alan Ulmus !!!! Bu kapsamda, Turkize'in guvenlik kaygilari tewel olarak Terorizm, uzan menzilli fueler ve title imha silahlarinin yayilmasi, Irticai faaliyetler, Bolgesel catismalardan kaynaklanmaktadir.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223355</th>\n",
       "      <td>223355</td>\n",
       "      <td>ff2c0ea4be7d7a16</td>\n",
       "      <td>\":::::::::::Nije ni slicna. Crnogorac je uz etnicku i regionalna oznaka slicno kao Sumadija, Vojvodina, itd., a Bunjevac je pod-etnicka oznaka za odredjenu skupinu Hrvata, slicno kao i Sokci, Boduli, Janjevci....vec sam to rekao pet puta ali cini se da ti to nikako ne ulazi u glavu. A \"\"velikohrvatsvo\"\" ne postoji, ono je izmisljeni pojam da bi se izjednacio sa pojmom 'Velika Srbija' koje su srpski nacionalisti sami izmislili i koristili.   \\n\\n \"</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>\":::::::::::Nine ni slicna. Crnogorac je up etnicku i regionalna oznaka slicno ka Sumadija, Vojvodina, it would., a Bunjevac je pod-etnicka oznaka za odredjenu skupinu Hrvata, slicno ka i Sorci, Noduli, Janjevci....ve sam to rekao pet put ali mini se da ti to nikako ne ulazi you glave. A \"\"velikohrvatsvo\"\" ne postoji, ono je izmisljeni pojam da bi se izjednacio sa pojmom 'Vedika Srbija' kore su srpski nacionalisti sami izmislili i koristili. \"</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223380</th>\n",
       "      <td>223380</td>\n",
       "      <td>ff4ae0cb03e213ca</td>\n",
       "      <td>OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTOMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTOMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF OMFG WTF</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTOMFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTOMFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF MFG WTF</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223405</th>\n",
       "      <td>223405</td>\n",
       "      <td>ff60bd49939604f4</td>\n",
       "      <td>Mein lieber Brendel, Ich bin auch deutscher Herkunft. Mein Vater ist Deutsch, meine Mutter aus Spanien. Ich meine die Nazi-Germanisten, nicht die Deutschen.</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Vein limber Trendel, Ch bin such deutsche Herkunft. Vein Later ist Deutsche, mine Utter as Spaniel. Ch mine die Nazi-Germanisten, nicht die Deutsche.</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223458</th>\n",
       "      <td>223458</td>\n",
       "      <td>ff9bbe71e8996418</td>\n",
       "      <td>سوال ۱۰ \\n سوال ۱۰ ۔ کیا اُم المومنین حضرت عائشہؓ کا مولاعلیؑ کے مقابل خروج حق تھا؟ \\n مستند روایات سے پتہ چلتا ہے کہ مولا علیؑ اور حضرت عائشہؓ کے مابین مخاصمت واقعہ افک کے بعد سے ہی شروع ہوگئی تھی جو کہ بڑھتے بڑھتے عداوت اختیار کہ گئی۔ دورانِ واقعہ افک حضوراکرمؐ نے غمغین حالت میں مولا علی ؑ سے مشورہ کیا تو مولا نے آپ کو غم و اضطراب سے بچانے کے لئے یہ مشورہ دیا کہ اللہ تعالیٰ نے آپ پر کچھ تنگی نہیں فرمائی اگر افواہوں کی بنا پر عائشہؓ کی طرف سے کچھ تکرر طبعی ہو گیا ہے تو عورتیں اور بہت ہیں۔ علاوہ ازیں آپ کا یہ تکرار اس طرح بھی رفع ہو سکتا ہے کہ بریرہؓ جو صدیقہ عائشہؓ کی کنیز ہیں۔ اُن سے اُنکے حالات کی تحقیق فرما لیجئے‘‘۔ مولا علیؑ کے اس مشورہ کا حضرت عائشہؓ کو بھی پتہ چل گیا تھا جس کی وجہ سے صدیقہ دِلی طور پر مولا ؑ سے ناخوش تھیں۔ \\n ہادی برحقؐ کی رحلت کے بعد مولا علی ؑ نے چھ ما ہ تک خلیفہ اول سے بیعت نہ کی۔ اِس دوران مسئلہ فدک بھی پیش آیا جس میں حضرت عائشہؓ نے سیدہ فاطمہؓ اور مولا علی ؑ کا بھی ساتھ نہ دیا اور اپنے والد حضرت ابو بکرؓ کی روایت کردہ حدیث کی تصدیق بھی کی۔مجھے مفتی صاحب کی اس بات سے قطعی طور پر اختلاف ہے کہ خلیفہ اول کے دور حکومت میں مولا علیؑ کے گھر کو آگ لگانے کے لئے کھڑیاں اس لئے جمع کی گئیں تھیں کیونکہ گھر میں منافقین اور فسادی جمع ہوگئے تھے۔ \\n\\n سبحان اللہ مفتی صاحب ایک طرف آپ فرما رہے ہیں کہ حضرت عائشہ کے گھر اہل بیت رسولؐ بھی بلا اذن داخل نہیں ہو سکتے تھے دوسری طرف آپ مولا علی ؑ کے گھر میں منافقین جمع ہونے کی خبر دے ر ہے ہیں۔ آپ کا یہ بیان کیا متضاد نہیں؟ کیا مولا کا گھر اہل بیت رسولؐ نہیں تھا؟ اپنی اس غلط بیانی پر ذرا خودی غور فرمائیے۔ نیز جن کو آپ مولا علی کے گھر میں منافقین اور فسادی کہہ رہے ہیں ان میں چند صحابہ کرام مثلاً حضرت عباسؓ بن عبد المطلب، حضرت زبیرؓ ،حضرت طلحہٰ، حضرت مقدارؓ ، حضرت سعد بن ابی وقاص اور خود مولا علیؑ بھی شامل تھے۔ نیز سیدہ فاطمۃ الزھرہؓ و حضرت حسنین ؑ بھی گھر میں موجود تھے ۔ لہٰذہ کیا مولا ؑ کے گھر کو آگ لگانے والے ارباب اختیا ر حضور اکرمؐ کی وصیت بھی بھول چکے تھے جس میں صحابہ کرام ؓ کو تلقین کی گئی تھی کہ میرے شہزادوں کا احترام ، محبت اور تعظیم کرنا۔ \\n\\n ان سب واقعات کے وقوع پذیر ہونے کے باوجود یہ سوال اٹھتا ہے کہ کیا مولا علیؑ اتنے بے بس اور لاچار تھے کہ لوگ ان کے گھر کو آگ لگانے کا پروگرام بنا رہے ہوں اور مولا ؑ خاموش ہیں؟ جواب میں عرض ہے کہ مولاؑ نہ تو خوفزدہ اور نہ ہی لاچار تھے۔ بھلا یہ کیسے ممکن ہے کہ جنگ اخزاب اور جنگ خیبر کا فاتح ایسے موقع پر خوفزدہ ہو۔ اصل بات مولا ؑ کی دور اندیش اور حضور اکرم ؐ کی آخری لمحات میں مولا ؑ کی گود میں وصیت تھی ’’علی میرے بعد تجھے مکر و ہات سے پالا پڑے گا تو دل تنگ نہ کرنا اورصبر کرنا‘‘حضورؐ کی یہ وصیت مولا کے لئے پتھر پر لکیر تھی پھر بھلا صبر کا دامن کیسے چھوڑ دیتے! \\n لکھنے والوں نے تو بہت کچھ لکھا ہے بلکہ لکھوایا گیا ہے۔ لیکن مولا ؑ چونکہ علم دھبی جو اللہ تعالیٰ کی طرف سے حضور اکرمؐ کے توسط سے ودیعت ہوا تھا سے بہتر طور پر سمجھ سکتے تھے کہ مناسب کیا ہے اورکیا نا مناسب ہے ۔ یہی وجہ تھی کہ مولا ؑ نے خلیفہ اول سے خلیفہ ثالث تک پورا پورا تعاون کیا۔ \\n\\n اب ہم آتے ہیں اصل سوال کی طرف کہ کیا اُم المومنین حضرت عائشہؓ کا مولا علیؓ کے مقابل خروج حق پر مبنی تھا؟ \\n اس سوال کا جواب بہت تفصیل طلب ہے۔ مختصراً عرض کردوں کہ ماں جی تمام امھات المومنین سے زیادہ علم رکھتی تھیں۔ آپ نے قرآن پاک کی مندرجہ ذیل آیات بھی یقناًپڑھی ہونگی:۔ \\n ۱:۔ \\t سورۃ الاحزاب (آیت ۶)۔ ترجمہ: نبیؐ مومنوں کے ساتھ خود ان کے نفس سے بھی زیادہ تعلق رکھتے ہیں۔ اور آپؐ کی بی بیاں ان کی ما یں ہیں۔ \\n ۲:۔ \\t سورۃ الاحزاب (آیت ۳۱-۳۲)۔ ترجمہ: \\t  ۳۱  اے نبی کی بی بیو تم معمولی عورتوں کی طرح نہیں اگر تم تقویٰ اختیار کرو۔ ۳۲: اور تم اپنے گھروں میں قرار سے رہو۔ \\n مذکورہ بالا احکام کی روشنی میں ممکن ہے حضرت عائشہؓ نے صحابہ کو تلقین کی ہو لیکن زیادہ احتمال یہی ہے کہ دیرنہ عدوات جو کہ انسانی فطرت ہے اورمشیروں کے غلط مشوروں سے خروج ہوا۔ ماں جی کو یقین تھا کہ مولا ؑ قاتلانِ عثمان میں شامل نہیں ہیں بلکہ مولا علیؑ نے آخری دم تک ؟؟؟؟ اپنے شہزادوں کے حضرت عثمانؓ کا ساتھ دیا۔ حضرت عائشہؓ ایک عالمہ فا ضلہ ام المومنین تھیں ایک عرصہ حضور اکرمؐ کر قربت میں گزارہ تھا اور اس پر فخر بھی کیا کرتی تھیں۔ \\n آپکے علم میں یہ دو حدیثیں تو ضرور ہونگی جن کا مفہوم یہ ہے:۔ \\n ۱: اے علی میرے بعد تمہارے ساتھ یہ اُمت دعا کرے گی تم میری ملت پر زندہ رہو گے۔ (کنز العمال علی متقی الجز سادس ۱۰۷۲) \\n ۲: \\t اے عائشہؓ میرے بعد تم ایک گروہ کی قیادت کرو گی جو نا حق ہو گا۔ مقام خواب پر تمہاری اونٹنی پر کتے بھونکیں گے۔ \\n ۳: \\t حضرت عمار بن یاسر کو ایک باغی گروہ قتل کرے گا۔ \\n اتنی واضح احادیث ہوتے ہوئے بھی مولا علیؑ کے خلاف خروج چہ معنی دارد۔ پھر مولاؑ بھی وہ جن کی شان شیخ سعدیؒ نے فرمایا۔ \\n بعدازمصطفےٰ در کل عالم \\t  نہ بُد فاضل ترو بہتر ز حیدر ؑ \\n بہر حال ماں جی نے خروج جن حالات اورجس وجہ سے کیا ظاہری تو ایک فطری عداوت ہی لگتی ہے۔ ورنہ مائیں تو اولاد کو صُلح و امن کا ہی مشورہ دیتی ہیں البتہ انکے خروج سے نہ صرف جنگ جمل ظہور پذیر ہوئی بلکہ جنگِ صفین، واقعہ حُرہ، سانحہٰ کربلا اور نہ جانے کتنے فتنے برپا ہوئے اور ہوتے رہیں گے۔یقیناً ماں جی کو اس حدیث مبارکہ کا بھی علم ہوگا جس میں حضور اکرمؐ نے فرمایا ’’عنقریب میرے اہل بیت میرے بعد میری اُمت سے قتل و غارت دیکھیں گے اور ہمارے سب سے زیادہ بغض رکھنے والے دشمن بنو اُمیہ، بنو المغیرہ و بنو مخدوم ہونگے (حدیث صحیح بخاری باب الفتن نمبر ۷)۔ ‘‘ \\n مندرجہ ذیل چیدہ چیدہ واقعات عالم اسلام میں بد ن</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>sol sol . why um lmwmnyn Hurt `y'shh[?] th mal`ly[?] why mqbl khrwj He th? mstnd rwy by path chat hy shh mal `ly[?] wr Hurt `y'shh[?] why mbyn mkhSmt we`h foh why b`d by hy show` hwy'y thy jaw shh brrhty brrhty `dwt khtyr shh by'y. dwrni we`h foh HDwrkhrm[?] ny GmGyn Hot my mal `ly [?] by mshwrh why to mal ny ap kw Gm w Darb by bchny why ly'y th mshwrh dy shh ll t`ly ny ap pr khchh tng nhyN army'y gr fwhwN why bn pr `y'shh[?] why Urf by khchh tkhrr Tb`y hw by hy to `wrtyN wr but hyp. `wh zy ap th th tkhrr s Try by rf` hw skit hy shh bryrh[?] jaw Sdyqh `y'shh[?] why khnyz hyp. un by unshy Hot why tHqyq from lyjy'y''. mal `ly[?] why s mshwrh th Hurt `y'shh[?] kw by path che by th js why wjc by Sdyqh daily Two pr mal [?] by nkhwsh thy. hay brHq[?] why rtlt why b`d mal `ly [?] ny che m h th khlyfh wl by by`t no why. is durn may'lh fikh by push ay js my Hurt `y'shh[?] ny syph fTmh[?] wr mal `ly [?] th by th no dy wr any old Hurt bw buhr[?] why rwy khrdh Hdyth why tSdyq by why.mjhy mufty Sob why s bt by T`y Two pr khtlf hy shh khlyfh wl why dr Hkhwmt my mal `ly[?] why gr kw ag luny why ly'y khhrryN s ly'y am` why by'N thy khywnkhh gr my mnfqyn wr fady am` hwy'y thy. sbHn ll mufty Sob yuh Urf ap from rhy hyp shh Hurt `y'shh why gr hl by rswl[?] by bl don dkl nhyN hw skhty thy dwsry Urf ap mal `ly [?] why gr my mnfqyn am` hwy why khor dy r hy hyp. ap th th by why mtd nhyN? why mal th gr hl by rswl[?] nhyN th? any s Glt bony pr dr khwdy Gr army'by. ny in kw ap mal `ly why gr my mnfqyn wr fady khhh rhy hyp n my cond SHbh khrm mthlan Hurt `bs[?] bn `bd lmTlb, Hurt zbyr[?] ,Hurt TlHh, Hurt mqdr[?] , Hurt s`d bn by wqS wr khud mal `ly[?] by sml thy. ny syph fum@ lzhrh[?] w Hurt Hsnyn [?] by gr my mwjwd thy . lhdhh why mal [?] why gr kw ag luny way rib khty r HDwr khrm[?] why wSyt by bowl chkhy thy js my SHbh khrm [?] kw tlqyn why by'y thy shh mary shhzdwN th Harm , mHbt wr t`Zyme khan. n sb we`t why www` pdhyr hwy why bwjwd th sol ttht hy shh why mal `ly[?] any by bs wr tchr thy shh leg n why gr kw ag luny th prwgrm bn rhy hwy wr mal [?] khmwsh hyp? job my `re hy shh mal[?] no to khwfzdh wr no hy tchr thy. hl th khysy mmkhn hy shh ing khz wr ing khybr th ftp ys mw` pr khwfzdh hw. Sl bt mal [?] why dr ndysh wr HDwr khrm [?] why akhry lmHt my mal [?] why god my wSyt thy ''`ly mary b`d thy mohr w ht by pl pray g to dl tng no khan wrSbr khan''HDwr[?] why th wSyt mal why ly'y phr pr lkhyr thy phr hl Sir th don khysy chhwrr duty! lkhhny wlwN ny to but khchh lkhh hy blkhh lkhhwy by hy. lyken mal [?] chwnkhh `lm doby jaw ll t`ly why Urf by HDwr khrm[?] why twsT by way`t hw th by bhtr Two pr smjh skhty thy shh msb why hy wrkhy n msb hy . why wjc thy shh mal [?] ny khlyfh wl by khlyfh tilth th pwr pwr t`in why. b hm at hyp Sl sol why Urf shh why um lmwmnyn Hurt `y'shh[?] th mal `ly[?] why mqbl khrwj He pr many th? s sol th job but tfSyl Tub hy. mkhtSran `re khrdwN shh my by tm met lmwmnyn by zydh `lm rkhhty thy. ap ny ran ph why mndrjh dhyal at by yqnanprrhy hwngy:. :. sir@ lHzb (at ). trjmh: by[?] mwmnwN why th khud n why ns by by zydh t`l rkhhty hyp. wr ap[?] why by by n why m N hyp. :. sir@ lHzb (at - ). trjmh: y by why by by tm m`owly `wrtwN why Try nhyN gr tm twy khtyr khrw. : wr tm any ghrwN my err by raw. mdhkhwrh bl Hkhm why rwshny my mmkhn hy Hurt `y'shh[?] ny SHbh kw tlqyn why hw lyken zydh Html why hy shh dyrnh `dwt jaw shh sny fort hy wrmshyrwN why Glt mshwrwN by khrwj hw. my by kw yqyn th shh mal [?] qtlni `than my sml nhyN hyp blkhh mal `ly[?] ny akhry dm th ???? any shhzdwN why Hurt `than[?] th th dy. Hurt `y'shh[?] yuh `tmh f Lh m lmwmnyn thy yuh `rah HDwr khrm[?] whr qrbt my gzrh th wr s pr fahr by why khrty thy. apkhy `lm my th do HdythyN to Drer hwngy in th mfhwm th hy:. : y `ly mary b`d tmhry th th ut d` chry by tm mary met pr zndh raw by. (khz l`ml `ly mtqy luz sds ) : y `y'shh[?] mary b`d tm yuh grwh why qydt khrw by jaw n He hw g. mm khwb pr tmhry wnttny pr khty bhwnkhyN by. : Hurt `mr bn yer kw yuh by grwh tl chry g. any DH Hdyth hwy hwy'y by mal `ly[?] why khaf khrwj che m`ny did. phr mal[?] by wh in why she shaykh s`dy[?] ny army. b`dzmSTfy dr hl `lm no bud fol try bhtr z Hydra [?] bar He my by ny khrwj in Hot wrjs wjc by why Chry to yuh fury `dwt hy lgth hy. wrnt my'N to old kw Sulu w mn th hy mshwrh duty hyp loth nkhy khrwj by no Serf ing sml Zhwr pdhyr hwy'y blkhh jngi Syn, we`h Hurt, snHh khrbl wr no any khtny ftny br hwy'y wr hwy rhy by.yqynan my by kw s Hdyth mbrkhh th by `lm wg js my HDwr khrm[?] ny army ''`nqryb mary hl by mary b`d mary ut by tl w Get dykhhyN by wr hory sb by zydh GD rkhhny way dshmn bow umph, bow lmGyrh w bow mkhdwm hwngy (Hdyth SHyH bkhry bb lftn nmbr ). '' mndrjh dhyal chydh chydh we`t `lm sum my bd n</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5272 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0  ... lang_score\n",
       "146            146  ...        0.0\n",
       "177            177  ...        0.0\n",
       "182            182  ...        0.0\n",
       "281            281  ...        0.0\n",
       "702            702  ...        0.0\n",
       "...            ...  ...        ...\n",
       "223351      223351  ...        0.0\n",
       "223355      223355  ...        0.0\n",
       "223380      223380  ...        0.0\n",
       "223405      223405  ...        0.0\n",
       "223458      223458  ...        0.0\n",
       "\n",
       "[5272 rows x 7 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[train['lang_score'] < 0.8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4y8ESWhCM64v"
   },
   "source": [
    "<p>Cette méthode ne me parait pas assez robuste. Je décide finalement de ne pas faire de tri même si on peut voir que certains commentaires n'apportent rien et ne sont d'ailleurs pas considérés comme \"toxiques\". De plus, étant donné que nous sommes sur une probématique multilingue, le fait d'avoir quelques commentaires dans d'autres langues que l'anglais ne devrait pas poser de problème au modèle lors de la phase d'entrainement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uGHfMWEfEZYY"
   },
   "source": [
    "## 2. Data augmentation<a class=\"anchor\" id=\"2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Comme dans le cadre de gestion d'objets de type \"image\", il est tout à fait possible de faire de la data augmentation en NLP. C'est ce que j'ai souhaité tester dans le cadre de ce projet et mesurer l'effet que cela pouvait avoir pour notre problématique. Cette augmentation de données peut se traduire de différentes formes : remplacement de mots par des synonymes, ajout ou remplacement de mots par d'autres considérés comme étant dans le même contexte... Pour cela, on utilise des dictionnaires pré enregistrés tirés de bert, xlnet ou encore wornet. C'est sur ce dernier que je me baserai pour faire des remplacements de mots par des synonymes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "obfXh2CIGR01"
   },
   "source": [
    "### 2.1 Installation des packages<a class=\"anchor\" id=\"2.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Tout d'abord, comme pour le nettoyage, la première partie est consacrée à l'installation des packages nécessaires et aux dictionnaires. Dans mon cas, c'est la librairie nlpaug qui est installée et qui sera utilisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5006,
     "status": "ok",
     "timestamp": 1594642491073,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "C6TaCr5kGUj5",
    "outputId": "a1acacf3-eafb-4519-a407-af058377c789"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nlpaug\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/6c/ca85b6bd29926561229e8c9f677c36c65db9ef1947bfc175e6641bc82ace/nlpaug-0.0.14-py3-none-any.whl (101kB)\n",
      "\r",
      "\u001b[K     |███▎                            | 10kB 17.8MB/s eta 0:00:01\r",
      "\u001b[K     |██████▌                         | 20kB 2.1MB/s eta 0:00:01\r",
      "\u001b[K     |█████████▊                      | 30kB 2.8MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████                   | 40kB 3.1MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▏               | 51kB 2.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████▍            | 61kB 2.7MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▋         | 71kB 3.0MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████▉      | 81kB 3.2MB/s eta 0:00:01\r",
      "\u001b[K     |█████████████████████████████   | 92kB 3.4MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 102kB 2.7MB/s \n",
      "\u001b[?25hInstalling collected packages: nlpaug\n",
      "Successfully installed nlpaug-0.0.14\n"
     ]
    }
   ],
   "source": [
    "!pip install nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1020,
     "status": "ok",
     "timestamp": 1594643768142,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "yC18YBx5GX3o",
    "outputId": "2d4b49b3-d02b-4fd4-bfeb-7cbf3c7bd9c1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.sentence as nas\n",
    "import nlpaug.flow as nafc\n",
    "\n",
    "from nlpaug.util import Action\n",
    "\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rZ071Q4VN_Zk"
   },
   "source": [
    "### 2.2 Méthode des synonymes<a class=\"anchor\" id=\"2.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Comme expliqué ci-dessus, c'est la méthode des synonymes qui sera employée et testée ici. On peut voir ci-dessous un exemple permettant d'illustrer tout l'intèrêt de cette méthode. Elle nous permet d'enrichir le corpus via de nouvelles features et donner l'espoir d'améliorer d'avantage le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 867,
     "status": "ok",
     "timestamp": 1594643771971,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "W8KRRPkgLDlE"
   },
   "outputs": [],
   "source": [
    "aug = naw.SynonymAug(aug_src='wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 651,
     "status": "ok",
     "timestamp": 1594643886847,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "MatWSuBcLoR-",
    "outputId": "86e3d584-e013-4527-dce0-3b15572081ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumps over the lazy dog .\n"
     ]
    }
   ],
   "source": [
    "text = 'The quick brown fox jumps over the lazy dog .'\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 717,
     "status": "ok",
     "timestamp": 1594643888911,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "p99iBTwWIJdj",
    "outputId": "7cb255c0-9953-425e-9175-d9eb4e84943a",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      "The quick brown fox jumps over the lazy dog .\n",
      "Augmented Text:\n",
      "The fast brown fox leap out over the faineant dog .\n"
     ]
    }
   ],
   "source": [
    "augmented_text = aug.augment(text)\n",
    "print(\"Original:\")\n",
    "print(text)\n",
    "print(\"Augmented Text:\")\n",
    "print(augmented_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Le résulat est sauvegardé dans une nouvelle colonne nommée \"comment_text_aug\". Cette démarche va me permettre de tester mes différents modèles sur 3 types d'input différents. Le but sera donc de trouver la meilleure combinaison possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1594646012430,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "1L_j9mwoslEU"
   },
   "outputs": [],
   "source": [
    "def make_augmentation(text):\n",
    "  text_aug = aug.augment(str(text))\n",
    "  return text_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVMTtEQ3NxjA"
   },
   "outputs": [],
   "source": [
    "train['comment_text_aug'] = train.progress_apply(lambda x: make_augmentation(x['comment_text_clean']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 555,
     "status": "ok",
     "timestamp": 1594647282158,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "Qo4Tifji0ryI",
    "outputId": "1874f0d9-a614-497d-f216-9b27a8175977",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>lang</th>\n",
       "      <th>comment_text_clean</th>\n",
       "      <th>lang_score</th>\n",
       "      <th>comment_text_aug</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Explanation Why the edits made under my username Hardcore Metallic Fan were reverted? They were not vandalisms, just closure on some As after I voted at New York Polls FoC. And please do not remove the template from the talk page since I am retired now. . . .</td>\n",
       "      <td>0.99</td>\n",
       "      <td>Explanation Why the edits made nether my username Hardcore Metallic Fan were reverted ? They were not vandalisms , just closure on some As after I voted at New House of york Polls FoC . And please do not remove the template from the talk pageboy since I make up adjourn now . . . .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>D'www! He matches this background colour I am seemingly stuck with. Thanks. (talk) : , January , (UTC)</td>\n",
       "      <td>0.98</td>\n",
       "      <td>500 ' www ! Helium match this background colour I am on the face of it stuck with . Thanks . ( talk ) : , Jan , ( coordinated universal time )</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>Hey man, I am really not trying to edit war. it is just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0.99</td>\n",
       "      <td>Hey man , I am really not trying to edit war . it is just that this cat is constantly removing relevant information and talking to pine tree state through edits instead of my talk page . Atomic number 2 seems to care more about the data formatting than the actual info .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good article nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>\" More I can not make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\" -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know. There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. it is listed in the relevant form eg Wikipedia:Good article nominations#Transport \"</td>\n",
       "      <td>0.99</td>\n",
       "      <td>\" More Single can not get any genuine suggestions on improvement - I wondered if the section statistics should be later on , or a subdivision of \" \" types of accidents \" \" - I think the references may need tidying indeed that they are all in the exact same format ie date format etc . I lav do that later on , if no - one else does first - if you have any preferences for formatting style on references or want to do it yourself delight let me acknowledge . There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up . it comprise listed in the relevant form eg Wikipedia : Good article nominations # Transport \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that is on?</td>\n",
       "      <td>0.98</td>\n",
       "      <td>You , sir , are my bomber . Any chance you call up what thomas nelson page that is on ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          comment_text_aug\n",
       "0           0  ...                                                                                                                                                                                                                                                                                                                                                                                                 Explanation Why the edits made nether my username Hardcore Metallic Fan were reverted ? They were not vandalisms , just closure on some As after I voted at New House of york Polls FoC . And please do not remove the template from the talk pageboy since I make up adjourn now . . . .\n",
       "1           1  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            500 ' www ! Helium match this background colour I am on the face of it stuck with . Thanks . ( talk ) : , Jan , ( coordinated universal time )\n",
       "2           2  ...                                                                                                                                                                                                                                                                                                                                                                                                            Hey man , I am really not trying to edit war . it is just that this cat is constantly removing relevant information and talking to pine tree state through edits instead of my talk page . Atomic number 2 seems to care more about the data formatting than the actual info .\n",
       "3           3  ...  \" More Single can not get any genuine suggestions on improvement - I wondered if the section statistics should be later on , or a subdivision of \" \" types of accidents \" \" - I think the references may need tidying indeed that they are all in the exact same format ie date format etc . I lav do that later on , if no - one else does first - if you have any preferences for formatting style on references or want to do it yourself delight let me acknowledge . There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up . it comprise listed in the relevant form eg Wikipedia : Good article nominations # Transport \"\n",
       "4           4  ...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   You , sir , are my bomber . Any chance you call up what thomas nelson page that is on ?\n",
       "\n",
       "[5 rows x 8 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Les jeux de données ainsi constitués sont sauvegardés afin de faciliter les différentes soumissions de modèles réalisées sur Kaggle dans le cadre de la compétition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8963,
     "status": "ok",
     "timestamp": 1594648561284,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "DwDZonAcdcH3"
   },
   "outputs": [],
   "source": [
    "train.to_csv('train_clean.csv')\n",
    "valid.to_csv('valid_clean.csv')\n",
    "test.to_csv('test_clean.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jBj4cWxxgTBP"
   },
   "source": [
    "## 3. Modélisation<a class=\"anchor\" id=\"3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Maintenant que notre data est correctement nettoyée, nous pouvons passer à la partie modélisation. Plusieurs tests vont être réalisés sur 2 types de modèles particulièrement adaptés à des contextes multilingues. Je vais découper ce chapitre en plusieurs étapes expliquant un cas général tout en faisant le lien avec le modèle final. Je détaillerai ensuite le mode opératoire effectué pour réaliser mes tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "G5RfFCTLp0CB"
   },
   "source": [
    "### 3.1 Configuration du TPU<a class=\"anchor\" id=\"3.1\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>La première étape consiste donc à configurer le TPU et à charger les différentes librairies comme transformers ou Keras depuis Tensorflow. Le code pour détecter le TPU a directement été repris depuis un autre notebook sur Kaggle. Son utilisation va nous permettre d'améliorer les temps de réponse en rendant les traitements 20 fois plus rapides environ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 341
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4871,
     "status": "ok",
     "timestamp": 1594912621290,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "wY_aTSDznHuM",
    "outputId": "35deac38-dd74-4aae-cb6d-bc0cc6aac622"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading https://files.pythonhosted.org/packages/27/3c/91ed8f5c4e7ef3227b4119200fc0ed4b4fd965b1f0172021c25701087825/transformers-3.0.2-py3-none-any.whl (769kB)\n",
      "Collecting tokenizers==0.8.1.rc1 (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/bf/9f/0bc9d97fc87b91a9f9be68623652734017caac523465ff47b980dd453ae4/tokenizers-0.8.1rc1-cp37-cp37m-win_amd64.whl (1.9MB)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/9c/d1/d2ecb51a8cb38c8278e77a2731c1366881e0dea9671f135d2625f15a73a4/regex-2020.7.14-cp37-cp37m-win_amd64.whl (268kB)\n",
      "Requirement already satisfied: packaging in c:\\anaconda3\\lib\\site-packages (from transformers) (19.0)\n",
      "Collecting sentencepiece!=0.1.92 (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/c7/fb817b7f0e8a4df1b1973a8a66c4db6fe10794a679cb3f39cd27cd1e182c/sentencepiece-0.1.91-cp37-cp37m-win_amd64.whl (1.2MB)\n",
      "Requirement already satisfied: requests in c:\\anaconda3\\lib\\site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: filelock in c:\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Collecting sacremoses (from transformers)\n",
      "  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\anaconda3\\lib\\site-packages (from transformers) (4.32.1)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\lib\\site-packages (from transformers) (1.18.2)\n",
      "Requirement already satisfied: six in c:\\anaconda3\\lib\\site-packages (from packaging->transformers) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.0)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\anaconda3\\lib\\site-packages (from requests->transformers) (1.24.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\lib\\site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\anaconda3\\lib\\site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\anaconda3\\lib\\site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: click in c:\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.0)\n",
      "Requirement already satisfied: joblib in c:\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (0.13.2)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py): started\n",
      "  Building wheel for sacremoses (setup.py): finished with status 'done'\n",
      "  Stored in directory: C:\\Users\\Guillaume Paris\\AppData\\Local\\pip\\Cache\\wheels\\29\\3c\\fd\\7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, regex, sentencepiece, sacremoses, transformers\n",
      "Successfully installed regex-2020.7.14 sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc1 transformers-3.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10175,
     "status": "ok",
     "timestamp": 1594912628492,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "o0_GghGerGXL"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import transformers\n",
    "from transformers import TFAutoModel, AutoTokenizer\n",
    "\n",
    "from tokenizers import BertWordPieceTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect hardware, return appropriate distribution strategy\n",
    "try:\n",
    "    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n",
    "    # set: this is always the case on Kaggle.\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Running on TPU ', tpu.master())\n",
    "except ValueError:\n",
    "    tpu = None\n",
    "\n",
    "if tpu:\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "else:\n",
    "    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "\n",
    "print(\"REPLICAS: \", strategy.num_replicas_in_sync)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hP2u4sVi2e6s"
   },
   "source": [
    "### 3.2 Fonction d'encodage<a class=\"anchor\" id=\"3.2\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Cette étape d'encodage est importante et doit être effectuée avant de lancer nos modèles. Elle permet d'obtenir une représentation vectorielle des mots et phrases de notre input. Elle se décompose en 2 étapes : \n",
    "    <ul>\n",
    "        <li><b>Tokenization :</b> l'idée générale est d'attribuer un index à chaque mot du corpus. Cette indexation se fait via un modèle pré-entrainé, le même que celui qui sera utilisé lors de la construction du modèle. Ici, la phase de tokenization se fera via la fonction \"get_tokenizer\". </li>\n",
    "        <li><b>Encodage des tokens :</b> c'est cette étape qui permet de récupérer une représentation vectorielle en fonction du contexte du mot transformé prédemment en token. On créé la fonction \"encode\" qui va permettre de faire ce travail. Elle utilise la méthode \"batch_encode_plus\" du tokenizer. A noter que chaque séquence doit être de la même taille, c'est pourquoi la méthode possède un paramètre permettant de définir le padding. Le résultat obtenu est directement stocké comme un tenseur.</li>\n",
    "    </ul>\n",
    "<p>Pour permettre d'effectuer ces calculs, et pour rendre la démarche facilement adaptable pour passer d'un modèle pré-entrainé à un autre, je vais utiliser le package \"AutoModels\" de HuggingFace. Ce package permet de récupérer directement l'architecture cible en fonction du nom ou du path du modèle pré-entrainé choisi dans la méthode \"from_pretrained\". Par exemple, si je décide de tester une architecture BERT, le fait de saisir \"bert-base-multilingual-cased\" en tant que modèle pré-entrainé permet à l'algorithme de comprendre qu'il s'agit de l'architecture BERT à remonter.\n",
    "<p>Avant de lancer cet encodage, on commence par définir les variables qui vont être utilisées dans le cadre de cette modélisation soit la taille du batch, la taille des séquences d'encodage (limité au 192 premiers caractères), le nombre d'époques lancées pour l'entrainement du modèle et surtout le modèle utilisé pour effectuer notre \"transfer learning\". Pour notre modèle final, la variable MODEL sera renseigné par 'jplu/tf-xlm-roberta-large'. C'est en effet via ce modèle pré-entrainé que j'ai récupéré les meilleurs résultats que je présenterai par la suite. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 489,
     "status": "ok",
     "timestamp": 1594847109736,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "DL7VnB1ktm15"
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "SEQUENCE_LENGTH = 192\n",
    "\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "#MODEL = 'distilbert-base-multilingual-cased'\n",
    "#MODEL = 'bert-base-multilingual-cased'\n",
    "MODEL = 'jplu/tf-xlm-roberta-large'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokenizer():\n",
    "    \"\"\"Get Tokenizer\"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "  \n",
    "    return tokenizer\n",
    "\n",
    "tokenizer = get_tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 510,
     "status": "ok",
     "timestamp": 1594911527925,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "XQz-5gu-1mxy"
   },
   "outputs": [],
   "source": [
    "def encode(texts, tokenizer, maxlen=512):\n",
    "    enc_di = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        return_attention_masks=False,\n",
    "        return_token_type_ids=False,\n",
    "        pad_to_max_length=True,\n",
    "        max_length=maxlen\n",
    "    )\n",
    "    return np.array(enc_di['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Maintenant que les fonctions permettant d'effectuer l'opération d'encodage sont définies, je vais pouvoir les appliquer à mes inputs. Pour rappel, depuis la phase de nettoyage, je dispose de 3 datasets possibles : non cleansé, nettoyé, et nettoyé avec data augmentation via des synonymes. L'idée est de tester mes modèles pré entrainés sur chacun des datasets disponibles et ainsi déterminer la meilleur combinaison possible. \n",
    "<p>Les tests me montreront que la data cleansée sans augmentation de données s'avère être la meilleure alternative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "#Text original\n",
    "#x_train = encode(train.comment_text.values, tokenizer, maxlen=SEQUENCE_LENGTH)\n",
    "#x_valid = encode(valid.comment_text.values, tokenizer, maxlen=SEQUENCE_LENGTH)\n",
    "#x_test = encode(test.content.values, tokenizer, maxlen=SEQUENCE_LENGTH)\n",
    "\n",
    "#Text clean\n",
    "x_train = encode(train.comment_text_clean.astype(str), tokenizer, maxlen=SEQUENCE_LENGTH)\n",
    "x_valid = encode(valid.comment_text_clean.astype(str), tokenizer, maxlen=SEQUENCE_LENGTH)\n",
    "x_test = encode(test.content_clean.astype(str), tokenizer, maxlen=SEQUENCE_LENGTH)\n",
    "\n",
    "#Text augmentation\n",
    "#x_train = encode(train.comment_text_aug.astype(str), tokenizer, maxlen=SEQUENCE_LENGTH)\n",
    "#x_valid = encode(valid.comment_text_clean.astype(str), tokenizer, maxlen=SEQUENCE_LENGTH)\n",
    "#x_test = encode(test.content_clean.astype(str), tokenizer, maxlen=SEQUENCE_LENGTH)\n",
    "\n",
    "y_train = train.toxic.values\n",
    "y_valid = valid.toxic.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Pour finaliser nos datasets, on utilise enfin l’API tf.data.Dataset de TensorFlow qui permet de créer un dataset à partir des données d’input et d'appliquer des transformations sur ces données. Organiser ses données de cette manière permet une utilisation optimale des inputs dans le pipeline, que ce soit en terme de temps d'exécution ou de mémoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((x_train, y_train))\n",
    "    .repeat()\n",
    "    .shuffle(2048)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "valid_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices((x_valid, y_valid))\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()\n",
    "    .prefetch(AUTO)\n",
    ")\n",
    "\n",
    "test_dataset = (\n",
    "    tf.data.Dataset\n",
    "    .from_tensor_slices(x_test)\n",
    "    .batch(BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Construction du modèle<a class=\"anchor\" id=\"3.3\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>La prochaine étape consiste à construire notre modèle. Il s'agit là d'un modèle de type réseau de neuronnes composé d'une couche embarquant le modèle transformer remonté via la fonction TFAutoModel. L'utilisation de la méthode \"from_pretained\" permet de récupérer les poids associés au modèle sélectionné.\n",
    "<p>La fonction build_model va donc construire et renvoyé le modèle à partir de l'architecture transformer du modèle à tester. Une couche de sortie de type binaire en relation avec notre problématique est ajoutée au modèle. Ce modèle est ensuite compilé sur l'optimiseur Adam avec une fonction de perte de type \"binary crossentropy\" et \"accuracy\" comme métrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(transformer, max_len=512):\n",
    "    \"\"\"\n",
    "    function for training model\n",
    "    \"\"\"\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    \n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Cette étape nous permet de compiler et charger le modèle sur le TPU. C'est également à ce niveau qu'on vient configurer l'architecture cible via la méthode \"from_pretrained\" pour remonter les poids du modèle pré-entrainées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with strategy.scope():\n",
    "    transformer_layer = TFAutoModel.from_pretrained(MODEL)\n",
    "    model = build_model(transformer_layer, max_len=SEQUENCE_LENGTH)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Entrainement<a class=\"anchor\" id=\"3.4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Si nous récapitulons : la data est chargée dans des datasets d'entrainement, de validation et de test, et le modèle a été compilé et chargé sur le TPU. Il est temps de passer à la partie entrainement. Cette partie va se décomposer en 2 étapes :\n",
    "    <ul>\n",
    "        <li>Entrainement du train_dataset avec validation sur le valid_dataset: on vient entrainer le jeu de données en anglais sur 3 époques</li>\n",
    "        <li>Entrainement du valid_dataset: on vient ajouter des étapes d'entrainement cette fois sur le jeu de validation qui se compose de données multilingues. Le jeu de données est plus petit et est entrainé sur le double d'époques, soit 6.</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = x_train.shape[0] // BATCH_SIZE\n",
    "train_history = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=n_steps,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps = x_valid.shape[0] // BATCH_SIZE\n",
    "train_history_2 = model.fit(\n",
    "    valid_dataset.repeat(),\n",
    "    steps_per_epoch=n_steps,\n",
    "    epochs=EPOCHS*2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Soumission du modèle<a class=\"anchor\" id=\"3.5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Nous arrivons à la fin de la démarche réalisée. Le modèle a été entrainé et je peux à présent prédire la target à partir du jeu de données test puis l'ajouter au dataframe avant de sauvegarder le résultat dans un fichier csv nommé \"submission.csv\". La soumission de ce résultat me permet d'obtenir mon score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv(\"../input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv\")\n",
    "sub['toxic'] = model.predict(test_dataset, verbose=1)\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 Mode opératoire et tests<a class=\"anchor\" id=\"3.6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>J'ai donc exposé dans les paragraphes précédents la méthodologie appliquée en présentant mon code pour le modèle qui a pu me remonter le meilleur score.\n",
    "<p>Cependant, d'autres tests ont été réalisés et m'ont permis d'effectuer une dizaine de soumissions. J'ai donc testé :\n",
    "    <ul>\n",
    "        <li>Le modèle pré-entrainé \"distilbert-base-multilingual-cased\" avec les 3 datasets disponibles</li>\n",
    "        <li>Le modèle pré-entrainé \"jplu/tf-xlm-roberta-large\" avec les 3 datasets disponibles</li>\n",
    "        <li>Le modèle pré-entrainé \"bert-base-multilingual-cased\" avec la colonne \"comment_text_clean\"</li>\n",
    "        <li>Le modèle pré-entrainé \"jplu/tf-xlm-roberta-large\" avec la colonne \"comment_text_clean\" en mettant un EarlyStopping pour lancer d'avantage d'époques lors de l'entrainement</li>\n",
    "        <li>Le modèle pré-entrainé \"jplu/tf-xlm-roberta-large\" avec la colonne \"comment_text_clean\" en rajoutant une couche de Dropout (voir code ci-dessous)</li>\n",
    "    </ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1594912689775,
     "user": {
      "displayName": "Guillaume Paris",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhFgth5dZ7cMcdqkhYtJQvs-5Wrpf-CGcwSFJo1eg=s64",
      "userId": "14849193279139033796"
     },
     "user_tz": -120
    },
    "id": "PhShUJKZ37gK"
   },
   "outputs": [],
   "source": [
    "def build_model(transformer, max_len=512):\n",
    "    \"\"\"\n",
    "    function for training model\n",
    "    \"\"\"\n",
    "    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "    \n",
    "    sequence_output = transformer(input_word_ids)[0]\n",
    "    cls_token = sequence_output[:, 0, :]\n",
    "    x = tf.keras.layers.Dropout(0.5)(cls_token) \n",
    "    out = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=input_word_ids, outputs=out)\n",
    "    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>A partir de là, j'ai réalisé un dernier test en gardant le meilleur modèle mais en l'entrainant sur d'avantage de données. A partir du fichier '../input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv' contenant près de 2 millions de commentaires, j'ai intégré au jeu d'entrainement les 250 000 premières lignes. Une transformation de la variable 'toxic' a été nécessaire car elle contenait une probabilité de toxicité et non un binaire. Ainsi, une probabilité supérieure à 50% entrainait une transformation de la valeur de la variable en 1 sinon 0. Ces données ont également été nettoyées sur le même principe que ce qui a été exposé ci-dessus dans la partie preprocessing. (voir code ci-dessous)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_1 = pd.read_csv('../input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')\n",
    "train_2 = pd.read_csv('../input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv')\n",
    "\n",
    "train_1 = train_1[['id','comment_text','toxic']]\n",
    "train_2 = train_2[['id','comment_text','toxic']]\n",
    "\n",
    "train_2 = train_2[0:250000]\n",
    "train_2['toxic'] = train_2['toxic'].apply(lambda x:0 if x<0.5 else 1)\n",
    "\n",
    "frames = [train_1,train_2]\n",
    "train = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GSTuv-NN4dgn"
   },
   "source": [
    "## 4. Résultats<a class=\"anchor\" id=\"4\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lEhoXJQ64k_P"
   },
   "source": [
    "<p>Précédemment, j'ai pu exposer chaque test réalisé. Chacun de ces tests m'ont permis d'obtenir un score sur la plateforme Kaggle qui a pu évoluer au fil des améliorations et modifications apportées. Parfois favorablement, parfois non. Ainsi, j'ai pu passer d'un score public à 0.8674 pour atteindre mon maximum à <b>0.9346</b>. \n",
    "<p>En comparaison avec les meilleurs résultats du concours, cela me place dans la 2ème partie de tableau autour de la 1000ème place (sur 1650), le meilleur score obtenu étant de 0.9556.\n",
    "<p>Par rapport aux discussions de la communauté, j'en ai déduit que le modèle pré-entrainé choisi (XLM Roberta) semblait être le modèle le plus approprié à notre problématique. En effet, ce modèle, basé sur BERT (Robust optimized BERT approach), est un ré-entrainement de BERT avec des améliorations sur la méthodologie et avec beaucoup plus de data et de temps de compute. Il est donc logique d'avoir de meilleurs résultats avec ce modèle qu'avec BERT ou DistilBERT.\n",
    "<p>Je pense donc que la différence peut se situer 2 choses : le volume de data pris en compte pour l'entrainement et le preprocessing des données. En effet, j'ai pu constater qu'une data nettoyée permettait d'avoir de meilleurs résultats. Peut être qu'une seconde phase de nettoyage plus poussée pourrait me permettre de faire évoluer le score à la hausse. Aussi, je n'ai utilisé qu'une petite partie du 2ème jeu d'entrainement mis à disposition. Néanmoins, les temps de traitement assez importants pour 1 run m'ont invité à ne pas prendre plus de données en considération. Il aurait peut être été intéressant de compléter mon jeu de données avec la totalité du second fichier dans l'espoir de voir mon score s'améliorer une nouvelle fois."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T8tMYk_Q4k5Y"
   },
   "source": [
    "## Conclusion<a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Ce projet a été pour moi très enrichissant sur plusieurs aspects. Tout d'abord, découvrir plus en profondeur ce que pourra m'apporter la plateforme Kaggle à l'avenir et le fonctionnement de ces compétitions très intéressantes. Ensuite, toute cette partie preprocessing de texte où j'ai pu découvrir de nouvelles librairies et faire quelque chose de différent par rapport à un projet précédent. Enfin, sur la mise en place de modèles de NLP pré-entrainés sur des problématiques multilingues et des cas d'usages qu'on peut retrouver dans la vie de tous les jours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources<a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Je me suis appuyé sur plusieurs kernels partagés par la communauté pour cette compétition :\n",
    "    <ul>\n",
    "        <li> https://www.kaggle.com/rftexas/cleaning-and-removing-mis-spells-from-texts</li>\n",
    "        <li> https://www.kaggle.com/mobassir/understanding-cross-lingual-models#Setup-TPU-configuration</li>\n",
    "        <li> https://www.kaggle.com/xhlulu/jigsaw-tpu-xlm-roberta/comments#Build-datasets-objects</li>\n",
    "    </ul>"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "P8.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "05e0431c4e634c818c9aef46bff2f095": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0988c5e38b5e4f88ab6ae45a80b8e7ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "0c34cb91fcfa4dd283d1261b7febd43a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0e714eae606944ec8df6e5af8a91d23c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11d9af2af5e94fa7a41414d203892e5c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "228b490e458f45c1ac6fde24e968e5d7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "24f76435292c4c14bc96bbc16582e9ad": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c32f1c4bf954050bc1d83e95b88cd96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_360ce49c810b4fa6bf6907c9583867a7",
      "placeholder": "​",
      "style": "IPY_MODEL_c491ed9d440e46d0a01af5d944adedd8",
      "value": " 466/466 [00:17&lt;00:00, 26.7B/s]"
     }
    },
    "360ce49c810b4fa6bf6907c9583867a7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "39e6f252d65c4809bcd183a240c4f41a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3fadbab676854585a1a08c5f54752fd4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_617015acf489420bac09ce33a6dfec17",
      "max": 5069051,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a8acf93bfa9a4b6e93c05f2d0b594503",
      "value": 5069051
     }
    },
    "416daa5ab47547aca11b3a81b65778b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7f863c5d7ff46a4819655facffc293c",
      "max": 513,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_92e655b165574a4da144ee49da35ffd0",
      "value": 513
     }
    },
    "50ec7af0f8cd4efdb21da3b57a051b73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e19298b8e7694af4a5f9054decdef5d4",
       "IPY_MODEL_64dd40b587c047e7a02cb9da63a98b8b"
      ],
      "layout": "IPY_MODEL_cb5daac5db884d14a73e081f69e25c11"
     }
    },
    "5f572c3aba2a4747b4f3e1943e1a6550": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "617015acf489420bac09ce33a6dfec17": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6477289c837646ad8b45a662d732ff93": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "64dd40b587c047e7a02cb9da63a98b8b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0c34cb91fcfa4dd283d1261b7febd43a",
      "placeholder": "​",
      "style": "IPY_MODEL_6477289c837646ad8b45a662d732ff93",
      "value": " 996k/996k [00:00&lt;00:00, 3.41MB/s]"
     }
    },
    "6e0b44e581ce4e668215fe459e11a712": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_416daa5ab47547aca11b3a81b65778b1",
       "IPY_MODEL_e7c38446d0c34fabb1d0c9ca4310f445"
      ],
      "layout": "IPY_MODEL_05e0431c4e634c818c9aef46bff2f095"
     }
    },
    "76253c87715e4db59d12e5e099f0ea5e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7db59f352fa644d8bccf02f37e8b7948": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "922a019c58ef415b8068fbeedd0872a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_11d9af2af5e94fa7a41414d203892e5c",
      "max": 466,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e3a03fb23a60490686b29f1b5bf26a3e",
      "value": 466
     }
    },
    "92e655b165574a4da144ee49da35ffd0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "a6b22ba5ff1846bd8278740703c8ddb6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7f863c5d7ff46a4819655facffc293c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a8acf93bfa9a4b6e93c05f2d0b594503": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b979f0d58e3e4e0393fcb49e020424c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c491ed9d440e46d0a01af5d944adedd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cb5daac5db884d14a73e081f69e25c11": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d3226c53ddd6496eaffff6c9960e00cf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_922a019c58ef415b8068fbeedd0872a8",
       "IPY_MODEL_2c32f1c4bf954050bc1d83e95b88cd96"
      ],
      "layout": "IPY_MODEL_fbd3e51b77304f7bb65901d9aefd5390"
     }
    },
    "d7fdc1e10a0a4a21a51534ccdbab4418": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3fadbab676854585a1a08c5f54752fd4",
       "IPY_MODEL_f8736953a87a4370a78161293762ab4e"
      ],
      "layout": "IPY_MODEL_5f572c3aba2a4747b4f3e1943e1a6550"
     }
    },
    "e19298b8e7694af4a5f9054decdef5d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_228b490e458f45c1ac6fde24e968e5d7",
      "max": 995526,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0988c5e38b5e4f88ab6ae45a80b8e7ee",
      "value": 995526
     }
    },
    "e3a03fb23a60490686b29f1b5bf26a3e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "e7c38446d0c34fabb1d0c9ca4310f445": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f5082e88bdbf4321b253196a4a75b48d",
      "placeholder": "​",
      "style": "IPY_MODEL_a6b22ba5ff1846bd8278740703c8ddb6",
      "value": " 513/513 [00:00&lt;00:00, 4.01kB/s]"
     }
    },
    "ed38496536e14221afe0c7182fea59b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_24f76435292c4c14bc96bbc16582e9ad",
      "max": 910749124,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_39e6f252d65c4809bcd183a240c4f41a",
      "value": 910749124
     }
    },
    "ed81e9cc64f840b2b2f3e2e64657b735": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f05a93a8ce444038a1e006c2536bfa73": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ed38496536e14221afe0c7182fea59b2",
       "IPY_MODEL_f3cea89e092546b1b69622733dbedb96"
      ],
      "layout": "IPY_MODEL_ed81e9cc64f840b2b2f3e2e64657b735"
     }
    },
    "f3cea89e092546b1b69622733dbedb96": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b979f0d58e3e4e0393fcb49e020424c1",
      "placeholder": "​",
      "style": "IPY_MODEL_76253c87715e4db59d12e5e099f0ea5e",
      "value": " 911M/911M [00:16&lt;00:00, 54.0MB/s]"
     }
    },
    "f5082e88bdbf4321b253196a4a75b48d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8736953a87a4370a78161293762ab4e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e714eae606944ec8df6e5af8a91d23c",
      "placeholder": "​",
      "style": "IPY_MODEL_7db59f352fa644d8bccf02f37e8b7948",
      "value": " 5.07M/5.07M [00:21&lt;00:00, 232kB/s]"
     }
    },
    "fbd3e51b77304f7bb65901d9aefd5390": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
